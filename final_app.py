import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
import openai
from twilio.rest import Client
from datetime import datetime, timedelta
import threading
import paho.mqtt.client as mqtt
import os

# ----- LOGO SVG -----
logo_svg = """
<svg width="64" height="64" viewBox="0 0 64 64" fill="none">
  <circle cx="32" cy="32" r="32" fill="url(#grad1)"/>
  <defs>
    <linearGradient id="grad1" x1="0" y1="0" x2="64" y2="64" gradientUnits="userSpaceOnUse">
      <stop stop-color="#43cea2"/>
      <stop offset="1" stop-color="#185a9d"/>
    </linearGradient>
  </defs>
  <g>
    <ellipse cx="32" cy="32" rx="22" ry="10" fill="#fff" fill-opacity="0.18"/>
    <ellipse cx="32" cy="32" rx="12" ry="22" fill="#fff" fill-opacity="0.10"/>
    <path d="M20 32a12 12 0 1 0 24 0 12 12 0 1 0 -24 0" fill="#fff" fill-opacity="0.7"/>
    <path d="M32 16v32M16 32h32" stroke="#185a9d" stroke-width="2" stroke-linecap="round"/>
    <circle cx="32" cy="32" r="6" fill="#43cea2" stroke="#185a9d" stroke-width="2"/>
  </g>
</svg>
"""

# MQTT Config
MQTT_BROKER = "broker.hivemq.com"
MQTT_PORT = 1883
MQTT_TOPIC = "digitaltwin/test/temperature"

# Secure config via environment
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")
TWILIO_SID = os.environ.get("TWILIO_SID")
TWILIO_AUTH = os.environ.get("TWILIO_AUTH")
TWILIO_FROM = os.environ.get("TWILIO_FROM")
TWILIO_TO = os.environ.get("TWILIO_TO")

# App state initialization
for key, default in [
    ("lang", "en"), ("scenario_step", 0), ("solution_idx", 0), ("theme", "dark"),
    ("mqtt_temp", None), ("mqtt_last", None), ("mqtt_started", False), ("sms_sent", False),
    ("feedback_list", [])
]:
    if key not in st.session_state:
        st.session_state[key] = default

# MQTT background thread
def on_connect(client, userdata, flags, rc):
    client.subscribe(MQTT_TOPIC)
def on_message(client, userdata, msg):
    try:
        val = float(msg.payload.decode())
        st.session_state["mqtt_temp"] = val
        st.session_state["mqtt_last"] = datetime.now()
    except Exception:
        pass
def mqtt_thread():
    client = mqtt.Client()
    client.on_connect = on_connect
    client.on_message = on_message
    try:
        client.connect(MQTT_BROKER, MQTT_PORT, 60)
        client.loop_forever()
    except Exception:
        pass
if not st.session_state["mqtt_started"]:
    t = threading.Thread(target=mqtt_thread, daemon=True)
    t.start()
    st.session_state["mqtt_started"] = True

# OpenAI setup
openai.api_key = OPENAI_API_KEY
def ask_llm(prompt, lang):
    system_en = """You are an expert AI assistant for an industrial digital twin platform called 'Smart Neural Digital Twin'.
This platform monitors various plant parameters in real-time, including temperature, pressure, and methane levels.
It provides advanced dashboards, predictive analytics (forecasting methane and temperature for the next 7 days),
scenario playback, alerts and fault logs, smart solutions for issues like methane leaks or pump failures,
KPIs, plant heatmaps, root cause analysis, and incident timelines.

When answering questions, prioritize information related to the 'Smart Neural Digital Twin' project and its data.
If asked about current sensor readings (like temperature, pressure, methane), or recent alerts, or daily metrics for vibration or levels, or future predictions for the next few hours/days, provide answers based on the context of the project's capabilities.
For example, if asked 'What is the current temperature?', you can state that the platform monitors live temperature via MQTT.
If asked about predictions, mention the 7-day forecast capability.

If the question is general and not directly related to the project, answer it to the best of your general knowledge.
"""
    system_ar = """Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒØ§Ø¡ ØµÙ†Ø§Ø¹ÙŠ Ø®Ø¨ÙŠØ± Ù„Ù…Ù†ØµØ© Ø§Ù„ØªÙˆØ£Ù… Ø§Ù„Ø±Ù‚Ù…ÙŠ Ø§Ù„ØµÙ†Ø§Ø¹ÙŠ Ø§Ù„Ù…Ø³Ù…Ø§Ø© 'Ø§Ù„ØªÙˆØ£Ù… Ø§Ù„Ø±Ù‚Ù…ÙŠ Ø§Ù„Ø¹ØµØ¨ÙŠ Ø§Ù„Ø°ÙƒÙŠ'.
ØªØ±Ø§Ù‚Ø¨ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ù†ØµØ© Ù…Ø¹Ù„Ù…Ø§Øª Ø§Ù„Ù…ØµÙ†Ø¹ Ø§Ù„Ù…Ø®ØªÙ„ÙØ© ÙÙŠ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„ÙØ¹Ù„ÙŠØŒ Ø¨Ù…Ø§ ÙÙŠ Ø°Ù„Ùƒ Ø¯Ø±Ø¬Ø© Ø§Ù„Ø­Ø±Ø§Ø±Ø© ÙˆØ§Ù„Ø¶ØºØ· ÙˆÙ…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ù…ÙŠØ«Ø§Ù†.
ØªÙˆÙØ± Ù„ÙˆØ­Ø§Øª ØªØ­ÙƒÙ… Ù…ØªÙ‚Ø¯Ù…Ø©ØŒ ÙˆØªØ­Ù„ÙŠÙ„Ø§Øª ØªÙ†Ø¨Ø¤ÙŠØ© (ØªØªÙ†Ø¨Ø£ Ø¨Ø§Ù„Ù…ÙŠØ«Ø§Ù† ÙˆØ¯Ø±Ø¬Ø© Ø§Ù„Ø­Ø±Ø§Ø±Ø© Ù„Ù„Ø£ÙŠØ§Ù… Ø§Ù„Ø³Ø¨Ø¹Ø© Ø§Ù„Ù‚Ø§Ø¯Ù…Ø©)ØŒ
ÙˆØ¥Ø¹Ø§Ø¯Ø© ØªØ´ØºÙŠÙ„ Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆÙ‡Ø§ØªØŒ ÙˆØ³Ø¬Ù„Ø§Øª Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª ÙˆØ§Ù„Ø£Ø¹Ø·Ø§Ù„ØŒ ÙˆØ­Ù„ÙˆÙ„ Ø°ÙƒÙŠØ© Ù„Ù…Ø´ÙƒÙ„Ø§Øª Ù…Ø«Ù„ ØªØ³Ø±Ø¨ Ø§Ù„Ù…ÙŠØ«Ø§Ù† Ø£Ùˆ Ø£Ø¹Ø·Ø§Ù„ Ø§Ù„Ù…Ø¶Ø®Ø§ØªØŒ
ÙˆÙ…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© (KPIs)ØŒ ÙˆØ®Ø±Ø§Ø¦Ø· Ø­Ø±Ø§Ø±Ø© Ø§Ù„Ù…ØµÙ†Ø¹ØŒ ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ø¨Ø¨ Ø§Ù„Ø¬Ø°Ø±ÙŠØŒ ÙˆØ§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ø²Ù…Ù†ÙŠØ© Ù„Ù„Ø­ÙˆØ§Ø¯Ø«.

Ø¹Ù†Ø¯ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©ØŒ Ø£Ø¹Ø· Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ© Ù„Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ØªØ¹Ù„Ù‚Ø© Ø¨Ù…Ø´Ø±ÙˆØ¹ 'Ø§Ù„ØªÙˆØ£Ù… Ø§Ù„Ø±Ù‚Ù…ÙŠ Ø§Ù„Ø¹ØµØ¨ÙŠ Ø§Ù„Ø°ÙƒÙŠ' ÙˆØ¨ÙŠØ§Ù†Ø§ØªÙ‡.
Ø¥Ø°Ø§ Ø³ÙØ¦Ù„Øª Ø¹Ù† Ù‚Ø±Ø§Ø¡Ø§Øª Ø§Ù„Ù…Ø³ØªØ´Ø¹Ø±Ø§Øª Ø§Ù„Ø­Ø§Ù„ÙŠØ© (Ù…Ø«Ù„ Ø¯Ø±Ø¬Ø© Ø§Ù„Ø­Ø±Ø§Ø±Ø©ØŒ Ø§Ù„Ø¶ØºØ·ØŒ Ø§Ù„Ù…ÙŠØ«Ø§Ù†)ØŒ Ø£Ùˆ Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª Ø§Ù„Ø£Ø®ÙŠØ±Ø©ØŒ Ø£Ùˆ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„ÙŠÙˆÙ…ÙŠØ© Ù„Ù„Ø§Ù‡ØªØ²Ø§Ø² Ø£Ùˆ Ø§Ù„Ù…Ø³ØªÙˆÙŠØ§ØªØŒ Ø£Ùˆ Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠØ© Ù„Ù„Ø³Ø§Ø¹Ø§Øª/Ø§Ù„Ø£ÙŠØ§Ù… Ø§Ù„Ù‚Ø§Ø¯Ù…Ø©ØŒ Ù‚Ø¯Ù… Ø¥Ø¬Ø§Ø¨Ø§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø³ÙŠØ§Ù‚ Ù‚Ø¯Ø±Ø§Øª Ø§Ù„Ù…Ø´Ø±ÙˆØ¹.
Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ØŒ Ø¥Ø°Ø§ Ø³ÙØ¦Ù„Øª 'ÙƒÙ… Ø¯Ø±Ø¬Ø© Ø§Ù„Ø­Ø±Ø§Ø±Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©ØŸ'ØŒ ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ø¥Ù„Ù‰ Ø£Ù† Ø§Ù„Ù…Ù†ØµØ© ØªØ±Ø§Ù‚Ø¨ Ø¯Ø±Ø¬Ø© Ø§Ù„Ø­Ø±Ø§Ø±Ø© Ø§Ù„Ø­ÙŠØ© Ø¹Ø¨Ø± MQTT.
Ø¥Ø°Ø§ Ø³ÙØ¦Ù„Øª Ø¹Ù† Ø§Ù„ØªÙˆÙ‚Ø¹Ø§ØªØŒ Ø§Ø°ÙƒØ± Ù‚Ø¯Ø±Ø© Ø§Ù„ØªÙ†Ø¨Ø¤ Ù„Ù…Ø¯Ø© 7 Ø£ÙŠØ§Ù….

Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¹Ø§Ù…Ù‹Ø§ ÙˆÙ„Ø§ ÙŠØªØ¹Ù„Ù‚ Ù…Ø¨Ø§Ø´Ø±Ø© Ø¨Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ØŒ Ø£Ø¬Ø¨ Ø¹Ù„ÙŠÙ‡ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù…Ø¹Ø±ÙØªÙƒ Ø§Ù„Ø¹Ø§Ù…Ø©.
"""
    system = system_en if lang == "en" else system_ar
    try:
        resp = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role":"system","content":system},
                {"role":"user","content":prompt}
            ],
            temperature=0.4,
            max_tokens=400,
        )
        return resp.choices[0].message.content
    except Exception as e:
        return "LLM Error: "+str(e)

# Twilio SMS
def send_sms(to, message):
    try:
        client = Client(TWILIO_SID, TWILIO_AUTH)
        message = client.messages.create(
            body=message,
            from_=TWILIO_FROM,
            to=to
        )
        return True, "Sent."
    except Exception as e:
        return False, str(e)

# Helper functions
def to_arabic_numerals(num):
    return str(num).translate(str.maketrans("0123456789", "Ù Ù¡Ù¢Ù£Ù¤Ù¥Ù¦Ù§Ù¨Ù©"))
def rtl_wrap(txt):
    if st.session_state["lang"] == "ar":
        return f'<div style="direction:rtl;text-align:right">{txt}</div>'
    else:
        return f'<div style="direction:ltr;text-align:left">{txt}</div>'
def show_logo():
    st.markdown(f'<div style="text-align:center;padding-bottom:1.2em;">{logo_svg}</div>', unsafe_allow_html=True)

# Translations
texts = {
    "en": {
        "app_title": "Smart Neural Digital Twin",
        "app_sub": "Intelligent Digital Plant Platform",
        "side_sections": [
            "Digital Twin", "Advanced Dashboard", "Predictive Analytics", "Scenario Playback",
            "Alerts & Fault Log", "Smart Solutions", "KPI Wall", "Plant Heatmap", "Root Cause Explorer", "AI Copilot Chat",
            "Live Plant 3D", "Incident Timeline", "Energy Optimization", "Future Insights", "Operator Feedback", "About"
        ],
        "lang_en": "English",
        "lang_ar": "Arabic",
        "solution_btn": "Next Solution",
        "logo_alt": "Smart Neural Digital Twin Logo",
        "about_header": "Our Story",
        "about_story": """Our journey began with a simple question: How can we detect gas leaks before they become disasters?\nWe tried every solution, even innovated with drones, and it worked. But we stopped and asked: Why wait for the problem at all?\nOur dream was to build a smart device that predicts danger before it happens. It wasnâ€™t impossible, just difficult. But we made the difficult easy with the smart neural digital twin that connects AI and plant data.\nToday, our platform is the first line of defense, standing apart from any traditional system because it predicts problems hours before they happen. Even days!\nThis is the future of industrial safetyâ€¦ and this is our project.""",
        "about_colorful": [
            ("#43cea2", "AI at the Core"),
            ("#fa709a", "Real-time Sensing"),
            ("#ffb347", "Predictive Analytics"),
            ("#8fd3f4", "Instant Actions"),
            ("#185a9d", "Peace of Mind"),
        ],
        "features": [
            "Interactive plant schematic & overlays",
            "Advanced dashboards & KPIs",
            "AI-driven fault detection & smart solutions",
            "Root-cause explorer & scenario playback",
            "Live 3D plant visualization",
            "Bilingual support & peak design"
        ],
        "howto_extend": [
            "Connect to real plant historian data",
            "Add custom plant schematics & overlays",
            "Integrate with control and alerting systems",
            "Deploy on secure internal networks"
        ],
        "developers": [
            ("Rakan Almarri", "rakan.almarri.2@aramco.com", "0532559664"),
            ("Abdulrahman Alzahrani", "abdulrahman.alzhrani.2@aramco.com", "0549202574")
        ],
        "contact": "Contact Info",
        "demo_note": "Demo use only: Not for live plant operation",
        "live3d_header": "Live Plant 3D",
        "live3d_intro": "Explore the interactive 3D model below. Use your mouse to zoom, rotate, and explore the plant!",
        "live3d_404": "The 3D model failed to load. View the static 3D plant image below.",
        "static_3d_caption": "Sample Plant 3D Visual",
        "solutions": [
            {
                "title": "Automated Methane Leak Response",
                "desc": "Integrate advanced sensors with automated shutdown logic to instantly contain future methane leaks.",
                "steps": ["Deploy new IoT sensors", "Implement AI detection", "Link to emergency shutdown", "Train operators"],
                "priority": "High", "effectiveness": "High", "time": "3 days", "cost": "$4,000", "savings": "$25,000/year",
                "icon": "ğŸ›¡ï¸"
            },
            {
                "title": "Pump Predictive Maintenance",
                "desc": "Monitor vibration and temperature to predict pump failures before they occur.",
                "steps": ["Install vibration sensors", "Run ML models", "Alert on anomaly", "Schedule just-in-time maintenance"],
                "priority": "Medium", "effectiveness": "High", "time": "1 week", "cost": "$5,000", "savings": "$18,000/year",
                "icon": "ğŸ”§"
            },
            {
                "title": "Energy Use Optimization",
                "desc": "AI analyzes compressor schedule to cut energy waste by 11%.",
                "steps": ["Analyze compressor cycles", "Optimize schedule", "Implement load shifting", "Track savings"],
                "priority": "High", "effectiveness": "Medium", "time": "2 weeks", "cost": "$6,000", "savings": "$32,000/year",
                "icon": "âš¡"
            },
        ]
    },
    "ar": {
        "app_title": "Ø§Ù„ØªÙˆØ£Ù… Ø§Ù„Ø±Ù‚Ù…ÙŠ Ø§Ù„Ø¹ØµØ¨ÙŠ Ø§Ù„Ø°ÙƒÙŠ",
        "app_sub": "Ù…Ù†ØµØ© Ø§Ù„Ù…ØµÙ†Ø¹ Ø§Ù„Ø°ÙƒÙŠ Ø§Ù„Ø±Ù‚Ù…ÙŠ",
        "side_sections": [
            "Ø§Ù„ØªÙˆØ£Ù… Ø§Ù„Ø±Ù‚Ù…ÙŠ", "Ù„ÙˆØ­Ø© Ø§Ù„Ù‚ÙŠØ§Ø¯Ø© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©", "Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„ØªÙ†Ø¨Ø¤ÙŠØ©", "ØªØ´ØºÙŠÙ„ Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ",
            "Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª ÙˆØ³Ø¬Ù„ Ø§Ù„Ø£Ø¹Ø·Ø§Ù„", "Ø§Ù„Ø­Ù„ÙˆÙ„ Ø§Ù„Ø°ÙƒÙŠØ©", "Ø¬Ø¯Ø§Ø± Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª", "Ø®Ø±ÙŠØ·Ø© Ø­Ø±Ø§Ø±Ø© Ø§Ù„Ù…ØµÙ†Ø¹", "Ù…Ø³ØªÙƒØ´Ù Ø§Ù„Ø³Ø¨Ø¨ Ø§Ù„Ø¬Ø°Ø±ÙŠ",
            "Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„ØµÙ†Ø§Ø¹ÙŠ", "Ù…ØµÙ†Ø¹ Ø«Ù„Ø§Ø«ÙŠ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯", "Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø­ÙˆØ§Ø¯Ø«", "ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø·Ø§Ù‚Ø©", "Ø±Ø¤Ù‰ Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠØ©", "Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ø§Ù„Ù…Ø´ØºÙ„", "Ø­ÙˆÙ„"
        ],
        "lang_en": "Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©",
        "lang_ar": "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©",
        "solution_btn": "Ø§Ù„Ø­Ù„ Ø§Ù„ØªØ§Ù„ÙŠ",
        "logo_alt": "Ø´Ø¹Ø§Ø± Ø§Ù„ØªÙˆØ£Ù… Ø§Ù„Ø±Ù‚Ù…ÙŠ Ø§Ù„Ø¹ØµØ¨ÙŠ Ø§Ù„Ø°ÙƒÙŠ",
        "about_header": "Ù‚ØµØªÙ†Ø§",
        "about_story": """Ø¨Ø¯Ø£Ù†Ø§ Ø±Ø­Ù„ØªÙ†Ø§ Ù…Ù† Ø³Ø¤Ø§Ù„ Ø¨Ø³ÙŠØ·: ÙƒÙŠÙ Ù†ÙƒØ´Ù ØªØ³Ø±Ø¨ Ø§Ù„ØºØ§Ø² Ù‚Ø¨Ù„ Ø£Ù† ÙŠØªØ­ÙˆÙ„ Ø¥Ù„Ù‰ ÙƒØ§Ø±Ø«Ø©ØŸ Ø¬Ø±Ø¨Ù†Ø§ ÙƒÙ„ Ø§Ù„Ø­Ù„ÙˆÙ„ØŒ ÙˆØ§Ø¨ØªÙƒØ±Ù†Ø§ Ø­ØªÙ‰ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø·Ø§Ø¦Ø±Ø§Øª Ø¨Ø¯ÙˆÙ† Ø·ÙŠØ§Ø± ÙˆÙ†Ø¬Ø­Ù†Ø§. Ù„ÙƒÙ† ÙˆÙ‚ÙÙ†Ø§ ÙˆØ³Ø£Ù„Ù†Ø§: Ù„Ù…Ø§Ø°Ø§ Ù†Ù†ØªØ¸Ø± Ø§Ù„Ù…Ø´ÙƒÙ„Ø© Ø£ØµÙ„Ø§Ù‹ØŸ\nØ­Ù„Ù…Ù†Ø§ ÙƒØ§Ù† Ø¨Ù†Ø§Ø¡ Ø¬Ù‡Ø§Ø² ÙŠØªÙˆÙ‚Ø¹ Ø§Ù„Ø®Ø·Ø± Ù‚Ø¨Ù„ Ø­Ø¯ÙˆØ«Ù‡. Ù„Ù… ÙŠÙƒÙ† Ù…Ø³ØªØ­ÙŠÙ„Ø§Ù‹ØŒ Ù„ÙƒÙ†Ù‡ ÙƒØ§Ù† ØµØ¹Ø¨Ù‹Ø§. Ø¬Ø¹Ù„Ù†Ø§ Ø§Ù„ØµØ¹Ø¨ Ø³Ù‡Ù„Ø§Ù‹ Ù…Ø¹ Ø§Ù„ØªÙˆØ£Ù… Ø§Ù„Ø±Ù‚Ù…ÙŠ Ø§Ù„Ø¹ØµØ¨ÙŠ Ø§Ù„Ø°ÙƒÙŠ Ø§Ù„Ø°ÙŠ ÙŠØ±Ø¨Ø· Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø¨Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØµÙ†Ø¹.\nØ§Ù„ÙŠÙˆÙ…ØŒ Ù…Ù†ØµØªÙ†Ø§ Ù‡ÙŠ Ø®Ø· Ø§Ù„Ø¯ÙØ§Ø¹ Ø§Ù„Ø£ÙˆÙ„ØŒ ÙˆØªØ®ØªÙ„Ù Ø¹Ù† Ø£ÙŠ Ù†Ø¸Ø§Ù… ØªÙ‚Ù„ÙŠØ¯ÙŠ Ù„Ø£Ù†Ù‡Ø§ ØªØªÙˆÙ‚Ø¹ Ø§Ù„Ù…Ø´ÙƒÙ„Ø© Ø¨Ø³Ø§Ø¹Ø§Øª Ù‚Ø¨Ù„ ÙˆÙ‚ÙˆØ¹Ù‡Ø§ØŒ ÙˆØ£Ø­ÙŠØ§Ù†Ù‹Ø§ Ø¨Ø£ÙŠØ§Ù…!\nÙ‡Ø°Ø§ Ù‡Ùˆ Ù…Ø³ØªÙ‚Ø¨Ù„ Ø§Ù„Ø£Ù…Ø§Ù† Ø§Ù„ØµÙ†Ø§Ø¹ÙŠ... ÙˆÙ‡Ø°Ø§ Ù‡Ùˆ Ù…Ø´Ø±ÙˆØ¹Ù†Ø§.""",
        "about_colorful": [
            ("#43cea2", "Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙÙŠ Ø§Ù„Ù‚Ù„Ø¨"),
            ("#fa709a", "Ø§Ø³ØªØ´Ø¹Ø§Ø± Ù„Ø­Ø¸ÙŠ"),
            ("#ffb347", "ØªØ­Ù„ÙŠÙ„Ø§Øª ØªÙ†Ø¨Ø¤ÙŠØ©"),
            ("#8fd3f4", "Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª ÙÙˆØ±ÙŠØ©"),
            ("#185a9d", "Ø±Ø§Ø­Ø© Ø§Ù„Ø¨Ø§Ù„"),
        ],
        "features": [
            "Ù…Ø®Ø·Ø· Ù…ØµÙ†Ø¹ ØªÙØ§Ø¹Ù„ÙŠ ÙˆØªØ±Ø§ÙƒØ¨ Ù…Ø¨Ø§Ø´Ø±",
            "Ù„ÙˆØ­Ø§Øª ÙˆÙ…Ø¤Ø´Ø±Ø§Øª Ù…ØªÙ‚Ø¯Ù…Ø©",
            "ÙƒØ´Ù Ø£Ø¹Ø·Ø§Ù„ Ø°ÙƒÙŠ ÙˆØ­Ù„ÙˆÙ„ ÙÙˆØ±ÙŠØ©",
            "Ù…Ø³ØªÙƒØ´Ù Ø§Ù„Ø³Ø¨Ø¨ Ø§Ù„Ø¬Ø°Ø±ÙŠ ÙˆØªØ´ØºÙŠÙ„ Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆÙ‡Ø§Øª",
            "Ø±Ø¤ÙŠØ© Ø«Ù„Ø§Ø«ÙŠØ© Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ù„Ù„Ù…ØµÙ†Ø¹",
            "Ø¯Ø¹Ù… Ù„ØºØªÙŠÙ† ÙˆØªØµÙ…ÙŠÙ… Ø¹ØµØ±ÙŠ"
        ],
        "howto_extend": [
            "Ø±Ø¨Ø· Ù…Ø¹ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØµÙ†Ø¹ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ©",
            "Ø¥Ø¶Ø§ÙØ© Ù…Ø®Ø·Ø·Ø§Øª ÙˆØªØ±Ø§ÙƒØ¨ Ù…Ø®ØµØµ",
            "Ø¯Ù…Ø¬ Ù…Ø¹ Ø£Ù†Ø¸Ù…Ø© Ø§Ù„ØªØ­ÙƒÙ… ÙˆØ§Ù„ØªÙ†Ø¨ÙŠÙ‡",
            "ØªØ´ØºÙŠÙ„ Ø¯Ø§Ø®Ù„ÙŠ Ø¢Ù…Ù†"
        ],
        "developers": [
            ("Ø±Ø§ÙƒØ§Ù† Ø§Ù„Ù…Ø¹Ø§Ø±ÙŠ", "rakan.almarri.2@aramco.com", "0532559664"),
            ("Ø¹Ø¨Ø¯Ø§Ù„Ø±Ø­Ù…Ù† Ø§Ù„Ø²Ù‡Ø±Ø§Ù†ÙŠ", "abdulrahman.alzhrani.2@aramco.com", "0549202574")
        ],
        "contact": "Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªÙˆØ§ØµÙ„",
        "demo_note": "Ù„Ù„Ø¹Ø±Ø¶ ÙÙ‚Ø·: ØºÙŠØ± Ù…Ø®ØµØµ Ù„Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„ÙØ¹Ù„ÙŠ",
        "live3d_header": "Ù…ØµÙ†Ø¹ Ø«Ù„Ø§Ø«ÙŠ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ù…Ø¨Ø§Ø´Ø±",
        "live3d_intro": "ØªÙØ§Ø¹Ù„ Ù…Ø¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø«Ù„Ø§Ø«ÙŠ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ø£Ø¯Ù†Ø§Ù‡. Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…Ø§ÙˆØ³ Ù„Ù„ØªØ­Ø±ÙŠÙƒ ÙˆØ§Ù„ØªÙƒØ¨ÙŠØ±.",
        "live3d_404": "ØªØ¹Ø°Ø± ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ØŒ Ø´Ø§Ù‡Ø¯ ØµÙˆØ±Ø© Ø§Ù„Ù…ØµÙ†Ø¹ Ø§Ù„Ø«Ù„Ø§Ø«ÙŠ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ø¨Ø§Ù„Ø£Ø³ÙÙ„.",
        "static_3d_caption": "Ù…Ø´Ù‡Ø¯ Ø«Ù„Ø§Ø«ÙŠ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ù„Ù…ØµÙ†Ø¹ ØµÙ†Ø§Ø¹ÙŠ",
        "solutions": [
            {
                "title": "Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø¢Ù„ÙŠØ© Ù„ØªØ³Ø±Ø¨ Ø§Ù„Ù…ÙŠØ«Ø§Ù†",
                "desc": "Ø¯Ù…Ø¬ Ø­Ø³Ø§Ø³Ø§Øª Ù…ØªØ·ÙˆØ±Ø© Ù…Ø¹ Ù…Ù†Ø·Ù‚ Ø¥ÙŠÙ‚Ø§Ù ØªÙ„Ù‚Ø§Ø¦ÙŠ Ù„Ø§Ø­ØªÙˆØ§Ø¡ Ø§Ù„ØªØ³Ø±Ø¨Ø§Øª ÙÙˆØ±Ø§Ù‹.",
                "steps": ["ØªØ±ÙƒÙŠØ¨ Ø­Ø³Ø§Ø³Ø§Øª Ø¥Ù†ØªØ±Ù†Øª Ø§Ù„Ø£Ø´ÙŠØ§Ø¡", "ØªÙØ¹ÙŠÙ„ ÙƒØ´Ù Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ", "Ø±Ø¨Ø· Ø¨Ø§Ù„Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø·Ø§Ø±Ø¦", "ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…Ø´ØºÙ„ÙŠÙ†"],
                "priority": "Ø¹Ø§Ù„ÙŠØ©", "effectiveness": "Ø¹Ø§Ù„ÙŠØ©", "time": "Ù£ Ø£ÙŠØ§Ù…", "cost": "$Ù¤Ù¬Ù Ù Ù ", "savings": "$Ù¢Ù¥Ù¬Ù Ù Ù /Ø³Ù†Ø©",
                "icon": "ğŸ›¡ï¸"
            },
            {
                "title": "ØµÙŠØ§Ù†Ø© Ø§Ø³ØªØ¨Ø§Ù‚ÙŠØ© Ù„Ù„Ù…Ø¶Ø®Ø§Øª",
                "desc": "Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø§Ù‡ØªØ²Ø§Ø²Ø§Øª ÙˆØ§Ù„Ø­Ø±Ø§Ø±Ø© Ù„Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ø£Ø¹Ø·Ø§Ù„ Ù‚Ø¨Ù„ ÙˆÙ‚ÙˆØ¹Ù‡Ø§.",
                "steps": ["ØªØ±ÙƒÙŠØ¨ Ø­Ø³Ø§Ø³Ø§Øª Ø§Ù„Ø§Ù‡ØªØ²Ø§Ø²", "ØªØ´ØºÙŠÙ„ Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ", "ØªÙ†Ø¨ÙŠÙ‡ Ø¹Ù†Ø¯ ÙˆØ¬ÙˆØ¯ Ø´Ø°ÙˆØ°", "Ø¬Ø¯ÙˆÙ„Ø© ØµÙŠØ§Ù†Ø© ÙÙˆØ±ÙŠØ©"],
                "priority": "Ù…ØªÙˆØ³Ø·Ø©", "effectiveness": "Ø¹Ø§Ù„ÙŠØ©", "time": "Ø£Ø³Ø¨ÙˆØ¹", "cost": "$Ù¥Ù¬Ù Ù Ù ", "savings": "$Ù¡Ù¨Ù¬Ù Ù Ù /Ø³Ù†Ø©",
                "icon": "ğŸ”§"
            },
            {
                "title": "ØªØ­Ø³ÙŠÙ† Ø§Ø³ØªÙ‡Ù„Ø§Ùƒ Ø§Ù„Ø·Ø§Ù‚Ø©",
                "desc": "ØªØ­Ù„Ù„ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø¶ÙˆØ§ØºØ· Ù„Ø®ÙØ¶ Ø§Ù„Ù‡Ø¯Ø± Ø¨Ù†Ø³Ø¨Ø© Ù¡Ù¡Ùª.",
                "steps": ["ØªØ­Ù„ÙŠÙ„ Ø¯ÙˆØ±Ø§Øª Ø§Ù„Ø¶ÙˆØ§ØºØ·", "ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¬Ø¯ÙˆÙ„Ø©", "ØªØ·Ø¨ÙŠÙ‚ Ù†Ù‚Ù„ Ø§Ù„Ø£Ø­Ù…Ø§Ù„", "Ù…ØªØ§Ø¨Ø¹Ø© Ø§Ù„ØªÙˆÙÙŠØ±"],
                "priority": "Ø¹Ø§Ù„ÙŠØ©", "effectiveness": "Ù…ØªÙˆØ³Ø·Ø©", "time": "Ø£Ø³Ø¨ÙˆØ¹Ø§Ù†", "cost": "$Ù¦Ù¬Ù Ù Ù ", "savings": "$Ù£Ù¢Ù¬Ù Ù Ù /Ø³Ù†Ø©",
                "icon": "âš¡"
            },
        ]
    }
}

# ----- THEME & CSS -----
if st.sidebar.button("ğŸŒ— Theme", key="themebtn"):
    st.session_state["theme"] = "light" if st.session_state["theme"] == "dark" else "dark"
if st.session_state["theme"] == "dark":
    st.markdown("""
    <style>
    html, body, [class*="css"]  { background: #232526 !important; color:#fff !important;}
    </style>
    """,unsafe_allow_html=True)
else:
    st.markdown("""
    <style>
    html, body, [class*="css"]  { background: #f3f8fc !important; color:#232526 !important;}
    </style>
    """,unsafe_allow_html=True)

st.markdown("""
    <style>
    @import url(\'https://fonts.googleapis.com/css2?family=Cairo:wght@700&family=Montserrat:wght@700&display=swap\');
    .peak-card {
        background: linear-gradient(135deg, #e0eafc 0%, #cfdef3 100%);
        border-radius: 18px;
        box-shadow: 0 8px 32px 0 rgba(31,38,135,.15);
        margin-bottom: 1.5em;
        padding: 1.5em 2em;
        transition: box-shadow 0.2s;
    }
    .peak-card:hover {
        box-shadow: 0 12px 38px 0 rgba(31,38,135,.28);
    }
    .kpi-card {
        background: linear-gradient(135deg, #43cea2 0%, #185a9d 100%);
        border-radius: 13px;
        color: #fff !important;
        font-size: 1.25em;
        font-weight: 700;
        box-shadow: 0 8px 24px 0 rgba(31,38,135,.10);
        padding: 1.3em 1.3em;
        text-align: center;
        margin-bottom: 1em;
    }
    .rtl {
        direction: rtl;
        text-align: right;
        font-family: \'Cairo\', sans-serif !important;
    }
    .ltr {
        direction: ltr;
        text-align: left;
        font-family: \'Montserrat\', sans-serif !important;
    }
    .sidebar-title {
        font-size: 2em !important;
        font-weight: 900 !important;
        color: #43cea2 !important;
        letter-spacing: 0.5px;
        margin-bottom: 0.2em !important;
    }
    .sidebar-subtitle {
        font-size: 1.15em !important;
        color: #cfdef3 !important;
        margin-bottom: 1em;
        margin-top: -.7em !important;
    }
    .gradient-header, .gradient-ar {
        font-weight: 900;
        font-size: 2.1em;
        background: linear-gradient(90deg,#43cea2,#185a9d 80%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        margin-bottom: 0.3em;
    }
    .timeline-step {
        border-left: 4px solid #43cea2;
        margin-left: 0.8em;
        padding-left: 1.2em;
        margin-bottom: 1em;
        position: relative;
    }
    .timeline-step:before {
        content: \'\';
        position: absolute;
        left: -14px;
        top: 0.18em;
        width: 18px;
        height: 18px;
        background: #43cea2;
        border-radius: 100%;
        border: 2px solid #fff;
    }
    .timeline-icon {
        font-size: 1.5em;
        margin-right: 0.5em;
        vertical-align: middle;
    }
    .about-bgcard {
        background: linear-gradient(120deg,#185a9d10,#43cea210 98%);
        border-radius: 22px;
        padding: 2.2em 2.1em 1.8em 2.1em;
        margin-top: 1.6em;
        margin-bottom: 2.2em;
        box-shadow: 0 7px 32px 0 rgba(31,38,135,.07);
        position: relative;
    }
    .about-story {
        font-size: 1.18em;
        font-weight: 600;
        margin-bottom: 2em;
        background: linear-gradient(90deg,#e0eafc,#8fd3f4 80%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        padding: 0.2em 0.1em;
    }
    .about-feature {
        font-weight: 700;
        font-size: 1.16em;
        margin: .45em 0 .14em 0;
    }
    .about-color {
        font-weight: 900;
        font-size: 1.20em;
        margin-bottom: .45em;
        display: inline-block;
        padding: .18em .9em;
        border-radius: 12px;
        margin-right: .9em;
    }
    .about-contact {
        font-size: 1.13em;
        margin-top: 1.9em;
        margin-bottom: .6em;
    }
    </style>
""", unsafe_allow_html=True)

# Sidebar
with st.sidebar:
    st.markdown(
        f"""<div class="sidebar-title">{texts[st.session_state["lang"]]["app_title"]}</div>
            <div class="sidebar-subtitle">{texts[st.session_state["lang"]]["app_sub"]}</div>""", unsafe_allow_html=True)
    lang_sel = st.radio(
        "", (texts["en"]["lang_en"], texts["en"]["lang_ar"]) if st.session_state["lang"] == "en" else (texts["ar"]["lang_en"], texts["ar"]["lang_ar"]),
        horizontal=True, index=0 if st.session_state["lang"] == "en" else 1
    )
    st.session_state["lang"] = "en" if lang_sel == texts["en"]["lang_en"] else "ar"
    section_list = texts[st.session_state["lang"]]["side_sections"]
    section = st.radio(" ", section_list, index=0)

lang = st.session_state["lang"]
T = texts[lang]
rtl = True if lang == "ar" else False

# Demo data
np.random.seed(1)
demo_df = pd.DataFrame({
    "time": pd.date_range(datetime.now() - timedelta(hours=24), periods=48, freq="30min"),
    "Temperature": np.random.normal(55, 6, 48),
    "Pressure": np.random.normal(7, 1.2, 48),
    "Methane": np.clip(np.random.normal(1.4, 0.7, 48), 0, 6)
})

# ========== MAIN SECTIONS ==========

if section == T["side_sections"][0]:  # Digital Twin (Live MQTT)
    show_logo()
    st.markdown(f'<div class="{"gradient-ar" if rtl else "gradient-header"}">{T["side_sections"][0]}</div>', unsafe_allow_html=True)
    try:
        st.image("realtime_streaming.png", caption=rtl_wrap("MQTT Real-Time Streaming Example" if lang=="en" else "Ù…Ø«Ø§Ù„ Ù…Ø´Ø§Ø±ÙƒØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­ÙŠØ©"))
    except Exception:
        st.image("https://cdn.pixabay.com/photo/2016/11/29/10/07/architecture-1868667_1280.jpg", caption=rtl_wrap("Demo Image"))
    st.markdown(rtl_wrap("Live Temperature (MQTT, topic: digitaltwin/test/temperature)" if lang=="en" else "Ù‚Ø±Ø§Ø¡Ø© Ø¯Ø±Ø¬Ø© Ø§Ù„Ø­Ø±Ø§Ø±Ø© Ø§Ù„Ø­ÙŠØ© (MQTT)"))
    temp = st.session_state["mqtt_temp"]
    if temp is not None:
        display_temp = to_arabic_numerals(round(temp,2)) if lang == "ar" else round(temp,2)
        st.metric(T["features"][0], f"{display_temp} Â°C", delta=None)
        # Trigger alert if temp > 60Â°C and send SMS
        if temp > 60 and not st.session_state["sms_sent"]:
            ok, msg = send_sms(TWILIO_TO, (f"ALERT: Plant temperature exceeded safe level! Temp={temp:.1f}Â°C" if lang=="en" else f"ØªÙ†Ø¨ÙŠÙ‡: Ø¯Ø±Ø¬Ø© Ø­Ø±Ø§Ø±Ø© Ø§Ù„Ù…ØµÙ†Ø¹ ØªØ¬Ø§ÙˆØ²Øª Ø§Ù„Ø­Ø¯ Ø§Ù„Ù…Ø³Ù…ÙˆØ­! Ø¯Ø±Ø¬Ø© Ø§Ù„Ø­Ø±Ø§Ø±Ø©={to_arabic_numerals(round(temp,1))}Â°Ù…"))
            st.session_state["sms_sent"] = True
            st.warning("âš ï¸ SMS Alert sent to supervisor!" if lang=="en" else "âš ï¸ ØªÙ… Ø¥Ø±Ø³Ø§Ù„ ØªÙ†Ø¨ÙŠÙ‡ SMS Ù„Ù„Ù…Ø´Ø±Ù!")
    else:
        st.info("Waiting for MQTT..." if lang=="en" else "ÙÙŠ Ø§Ù†ØªØ¸Ø§Ø± Ø¨ÙŠØ§Ù†Ø§Øª MQTT...")
    st.caption(f"{'Last update' if lang=='en' else 'Ø¢Ø®Ø± ØªØ­Ø¯ÙŠØ«'}: {st.session_state['mqtt_last'] if st.session_state['mqtt_last'] else 'N/A'}")

elif section == T["side_sections"][1]:  # Advanced Dashboard
    show_logo()
    st.markdown(f'<div class="{"gradient-ar" if rtl else "gradient-header"}">{T["side_sections"][1]}</div>', unsafe_allow_html=True)
    st.markdown(rtl_wrap("KPIs and live trends for the plant." if lang=="en" else "Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª ÙˆØ§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª Ø§Ù„Ø­ÙŠØ© Ù„Ù„Ù…ØµÙ†Ø¹."))
    fig = px.line(demo_df, x="time", y=["Temperature", "Pressure", "Methane"], labels={"value":"Reading", "variable":"Tag"})
    fig.update_layout(legend_title_text="Tag", height=350)
    st.plotly_chart(fig, use_container_width=True)

elif section == T["side_sections"][2]:  # Predictive Analytics
    show_logo()
    st.markdown(f'<div class="{"gradient-ar" if rtl else "gradient-header"}">{T["side_sections"][2]}</div>', unsafe_allow_html=True)
    st.markdown(rtl_wrap("Forecast of methane and temperature for next 7 days." if lang=="en" else "ØªÙˆÙ‚Ø¹ Ø§Ù„Ù…ÙŠØ«Ø§Ù† ÙˆØ¯Ø±Ø¬Ø© Ø§Ù„Ø­Ø±Ø§Ø±Ø© Ù„Ù„Ø£ÙŠØ§Ù… Ø§Ù„Ø³Ø¨Ø¹Ø© Ø§Ù„Ù‚Ø§Ø¯Ù…Ø©."))
    days = pd.date_range(datetime.now(), periods=7)
    forecast = pd.DataFrame({
        "Day": days,
        "Methane": np.linspace(1.2, 4.5, 7) + np.random.normal(0, 0.2, 7),
        "Temp": np.linspace(55, 63, 7) + np.random.normal(0, 1, 7)
    })
    st.line_chart(forecast.set_index("Day"))

elif section == T["side_sections"][3]:  # Scenario Playback
    show_logo()
    st.markdown(f'<div class="{"gradient-ar" if rtl else "gradient-header"}">{T["side_sections"][3]}</div>', unsafe_allow_html=True)
    st.markdown(rtl_wrap("Replay plant incident scenarios hour by hour." if lang=="en" else "ØªØ´ØºÙŠÙ„ Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆÙ‡Ø§Øª Ø§Ù„Ø­ÙˆØ§Ø¯Ø« Ø³Ø§Ø¹Ø© Ø¨Ø³Ø§Ø¹Ø©."))
    step = st.slider(T["side_sections"][3], 0, 23, 0)
    st.markdown(rtl_wrap(f"Scenario at hour {step}" if lang=="en" else f"Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ Ø¹Ù†Ø¯ Ø§Ù„Ø³Ø§Ø¹Ø© {to_arabic_numerals(step)}"))
    chart_data = np.cumsum(np.random.randn(24)) + 50
    st.line_chart(chart_data[:step+1])

elif section == T["side_sections"][4]:  # Alerts & Fault Log
    show_logo()
    st.markdown(f'<div class="{"gradient-ar" if rtl else "gradient-header"}">{T["side_sections"][4]}</div>', unsafe_allow_html=True)
    alert_log = pd.DataFrame([
        {"Time":"2025-07-01 05:00","Type":("High Temp" if lang=="en" else "Ø­Ø±Ø§Ø±Ø© Ø¹Ø§Ù„ÙŠØ©"),"Status":("Open" if lang=="en" else "Ù…ÙØªÙˆØ­")},
        {"Time":"2025-07-01 03:32","Type":("Methane Spike" if lang=="en" else "Ø§Ø±ØªÙØ§Ø¹ Ø§Ù„Ù…ÙŠØ«Ø§Ù†"),"Status":("Closed" if lang=="en" else "Ù…ØºÙ„Ù‚")},
        {"Time":"2025-06-30 22:10","Type":("Low Flow" if lang=="en" else "ØªØ¯ÙÙ‚ Ù…Ù†Ø®ÙØ¶"),"Status":("Closed" if lang=="en" else "Ù…ØºÙ„Ù‚")},
    ])
    st.table(alert_log)

elif section == T["side_sections"][5]:  # Smart Solutions
    show_logo()
    idx = st.session_state["solution_idx"]
    solutions = T["solutions"]
    sol = solutions[idx]
    steps_html = "".join([f"<li>{s}</li>" for s in sol["steps"]])
    st.markdown(f"""
    <div class="peak-card">
        <div style="font-size:2em;">{sol["icon"]}</div>
        <b style="font-size:1.3em">{sol["title"]}</b>
        <div style="margin:0.8em 0 0.5em 0;">{sol["desc"]}</div>
        <ul style="margin-bottom:0.7em;">{steps_html}</ul>
        <div style="display:flex;gap:0.9em;flex-wrap:wrap;">
            <span style="background:#185a9d12;padding:0.3em 1em;border-radius:6px;">{(\'Priority\' if lang==\'en\' else \'Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©\')}: {sol[\'priority\]}</span>
            <span style="background:#185a9d12;padding:0.3em 1em;border-radius:6px;">{(\'Effectiveness\' if lang==\'en\' else \'Ø§Ù„ÙØ¹Ø§Ù„ÙŠØ©\')}: {sol[\'effectiveness\]}</span>
            <span style="background:#185a9d12;padding:0.3em 1em;border-radius:6px;">{(\'Time\' if lang==\'en\' else \'Ø§Ù„Ù…Ø¯Ø©\')}: {sol[\'time\]}</span>
            <span style="background:#185a9d12;padding:0.3em 1em;border-radius:6px;">{(\'Cost\' if lang==\'en\' else \'Ø§Ù„ØªÙƒÙ„ÙØ©\')}: {sol[\'cost\]}</span>
            <span style="background:#185a9d12;padding:0.3em 1em;border-radius:6px;">{(\'Savings\' if lang==\'en\' else \'Ø§Ù„ØªÙˆÙÙŠØ±\')}: {sol[\'savings\]}</span>
        </div>
    </div>
    """, unsafe_allow_html=True)
    if st.button(T["solution_btn"], key=f"solution-next-{idx}"):
        st.session_state["solution_idx"] = (idx + 1) % len(solutions)

elif section == T["side_sections"][6]:  # KPI Wall
    show_logo()
    kpis = [
        ("Overall Efficiency", "âœ…", "#8fd3f4"),
        ("Energy Used (MWh)", "âš¡", "#fe8c00"),
        ("Water Saved (mÂ³)", "ğŸ’§", "#43cea2"),
        ("Incidents This Year", "ğŸ›‘", "#fa709a")
    ] if lang == "en" else [
        ("Ø§Ù„ÙƒÙØ§Ø¡Ø© Ø§Ù„Ø¹Ø§Ù…Ø©", "âœ…", "#8fd3f4"),
        ("Ø§Ù„Ø·Ø§Ù‚Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© (Ù…ÙŠØºØ§ÙˆØ§Ø·)", "âš¡", "#fe8c00"),
        ("Ø§Ù„Ù…Ø§Ø¡ Ø§Ù„Ù…ÙˆÙØ± (Ù…Â³)", "ğŸ’§", "#43cea2"),
        ("Ø§Ù„Ø­ÙˆØ§Ø¯Ø« Ù‡Ø°Ø§ Ø§Ù„Ø¹Ø§Ù…", "ğŸ›‘", "#fa709a")
    ]
    vals = [96, 272, 62, 1]
    goals = [98, 250, 70, 0]
    st.markdown("<div style=\'display:flex;gap:1.3em;flex-wrap:wrap;\'>", unsafe_allow_html=True)
    for i, (name, icon, color) in enumerate(kpis):
        display_val = to_arabic_numerals(vals[i]) if lang == "ar" else str(vals[i])
        display_goal = to_arabic_numerals(goals[i]) if lang == "ar" else str(goals[i])
        st.markdown(f"""<div class="kpi-card" style="background:{color}c0;">
            <span style="font-size:2.1em;">{icon}</span><br>
            <b>{name}</b><br>
            <span style="font-size:2.3em;font-weight:900">{display_val}</span>
            <div style="font-size:.95em;color:#222;">{(\'Goal\' if lang==\'en\' else \'Ø§Ù„Ù‡Ø¯Ù\')}: {display_goal}}</div>
        </div>""", unsafe_allow_html=True)
    st.markdown("</div>", unsafe_allow_html=True)

elif section == T["side_sections"][7]:  # Plant Heatmap
    show_logo()
    st.markdown(f'<div class="{"gradient-ar" if rtl else "gradient-header"}">{T["side_sections"][7]}</div>', unsafe_allow_html=True)
    st.markdown(rtl_wrap("High temperature and pressure zones are highlighted below." if lang=="en" else "Ø§Ù„Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ø­Ø±Ø¬Ø© Ù„Ù„Ø­Ø±Ø§Ø±Ø© ÙˆØ§Ù„Ø¶ØºØ· Ù…ÙˆØ¶Ø­Ø© Ø£Ø¯Ù†Ø§Ù‡."))
    z = np.random.uniform(25, 70, (8, 10))
    fig = go.Figure(data=go.Heatmap(z=z, colorscale=\'YlOrRd\', colorbar=dict(title=(\'Temp Â°C\' if lang==\'en\' else \'Ø­Ø±Ø§Ø±Ø©\'))))
    fig.update_layout(height=320, margin=dict(l=12, r=12, t=20, b=20))
    st.plotly_chart(fig, use_container_width=True)

elif section == T["side_sections"][8]:  # Root Cause Explorer
    show_logo()
    st.markdown(f'<div class="{"gradient-ar" if rtl else "gradient-header"}">{T["side_sections"][8]}</div>', unsafe_allow_html=True)
    st.markdown(rtl_wrap("Trace issues to their origin. Sample propagation path shown below." if lang=="en" else "ØªØªØ¨Ø¹ Ø§Ù„Ù…Ø´ÙƒÙ„Ø§Øª Ø¥Ù„Ù‰ Ø£ØµÙ„Ù‡Ø§. Ø³Ù„Ø³Ù„Ø© Ø§Ù„Ø³Ø¨Ø¨ ÙˆØ§Ù„Ù†ØªÙŠØ¬Ø© Ø£Ø¯Ù†Ø§Ù‡."))
    st.markdown("""
    <div style="margin-top:1em;display:flex;justify-content:center;">
    <svg width="340" height="180" viewBox="0 0 340 180">
      <rect x="20" y="70" width="80" height="38" rx="12" fill="#43cea2" opacity="0.89"/>
      <rect x="140" y="30" width="90" height="38" rx="12" fill="#ffb347" opacity="0.91"/>
      <rect x="140" y="110" width="90" height="38" rx="12" fill="#fa709a" opacity="0.91"/>
      <rect x="260" y="70" width="60" height="38" rx="12" fill="#8fd3f4" opacity="0.91"/>
      <text x="60" y="93" font-size="1.2em" fill="#fff" font-family="Cairo,Montserrat" text-anchor="middle">{}</text>
      <text x="185" y="53" font-size="1.1em" fill="#fff" font-family="Cairo,Montserrat" text-anchor="middle">{}</text>
      <text x="185" y="133" font-size="1.1em" fill="#fff" font-family="Cairo,Montserrat" text-anchor="middle">{}</text>
      <text x="290" y="93" font-size="1.1em" fill="#185a9d" font-family="Cairo,Montserrat" text-anchor="middle">{}</text>
      <line x1="100" y1="89" x2="140" y2="49" stroke="#43cea2" stroke-width="3" marker-end="url(#arrow)"/>
      <line x1="100" y1="89" x2="140" y2="129" stroke="#43cea2" stroke-width="3" marker-end="url(#arrow)"/>
      <line x1="230" y1="49" x2="260" y2="89" stroke="#ffb347" stroke-width="3" marker-end="url(#arrow)"/>
      <line x1="230" y1="129" x2="260" y2="89" stroke="#fa709a" stroke-width="3" marker-end="url(#arrow)"/>
      <defs>
        <marker id="arrow" markerWidth="10" markerHeight="10" refX="8" refY="3" orient="auto" markerUnits="strokeWidth">
          <path d="M0,0 L0,6 L9,3 z" fill="#185a9d" />
        </marker>
      </defs>
    </svg>
    </div>
    """.format(
        "Root: Methane leak" if lang=="en" else "Ø§Ù„Ø¬Ø°Ø±: ØªØ³Ø±Ø¨ Ù…ÙŠØ«Ø§Ù†",
        "Compressor 2 Fault" if lang=="en" else "Ø¹Ø·Ù„ Ø§Ù„Ø¶Ø§ØºØ· Ù¢",
        "Pump Overload" if lang=="en" else "ØªØ­Ù…ÙŠÙ„ Ø²Ø§Ø¦Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¶Ø®Ø©",
        "Incident: Shutdown" if lang=="en" else "Ø­Ø§Ø¯Ø«: Ø¥ÙŠÙ‚Ø§Ù"
    ), unsafe_allow_html=True)

elif section == T["side_sections"][9]:  # AI Copilot Chat (LLM)
    show_logo()
    st.markdown(f'<div class="{"gradient-ar" if rtl else "gradient-header"}">{T["side_sections"][9]}</div>', unsafe_allow_html=True)
    st.markdown(rtl_wrap("Ask the AI about plant issues, troubleshooting, or improvements." if lang=="en" else "Ø§Ø³Ø£Ù„ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„ØµÙ†Ø§Ø¹ÙŠ Ø¹Ù† Ø§Ù„Ø£Ø¹Ø·Ø§Ù„ Ø£Ùˆ Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª Ø£Ùˆ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„."))
    user_prompt = st.text_input(("Ask AI a question..." if lang=="en" else "Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ø§Ù‹ Ù„Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„ØµÙ†Ø§Ø¹ÙŠ..."), key="ai_input")
    if user_prompt:
        with st.spinner("Thinking..." if lang=="en" else "ÙŠÙÙƒØ±..."):
            answer = ask_llm(user_prompt, lang)
        st.markdown(f"**AI:** {answer}")

elif section == T["side_sections"][10]:  # Live Plant 3D
    show_logo()
    st.markdown(f'<div class="{"gradient-ar" if rtl else "gradient-header"}">{T["live3d_header"]}</div>', unsafe_allow_html=True)
    st.markdown(rtl_wrap(T["live3d_intro"]), unsafe_allow_html=True)
    try:
        st.components.v1.iframe(
            "https://sketchfab.com/models/6ebc4e240be94b8caa1e1e6b0f2e3e7b/embed", height=480, scrolling=True
        )
        st.markdown(
            rtl_wrap(
                \'<sup>3D model courtesy of <a href="https://sketchfab.com" target="_blank">Sketchfab</a></sup>\' if lang=="en"
                else \'<sup>Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø«Ù„Ø§Ø«ÙŠ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ù…Ù‚Ø¯Ù… Ù…Ù† <a href="https://sketchfab.com" target="_blank">Sketchfab</a></sup>\'
            ),
            unsafe_allow_html=True
        )
    except Exception:
        st.markdown(f'<div class="peak-card" style="background:#fa709a22">{T["live3d_404"]}</div>', unsafe_allow_html=True)
    st.image(
        "https://cdn.pixabay.com/photo/2016/11/29/10/07/architecture-1868667_1280.jpg",
        caption=rtl_wrap(T["static_3d_caption"])
    )

elif section == T["side_sections"][11]:  # Incident Timeline
    show_logo()
    st.markdown(f'<div class="{"gradient-ar" if rtl else "gradient-header"}">{T["side_sections"][11]}</div>', unsafe_allow_html=True)
    timeline_steps = [
        ("2025-06-30 11:23", "ğŸ›‘", "Methane leak detected at Compressor 2. Emergency shutdown triggered."),
        ("2025-06-30 10:58", "âš ï¸", "Flow rate anomaly at Pump 1. Operator notified."),
        ("2025-06-30 10:50", "â„¹ï¸", "Temperature rising at Reactor. Trend within safe limits.")
    ] if lang == "en" else [
        ("2025-06-30 11:23", "ğŸ›‘", "Ø§ÙƒØªØ´Ø§Ù ØªØ³Ø±Ø¨ Ù…ÙŠØ«Ø§Ù† Ø¹Ù†Ø¯ Ø§Ù„Ø¶Ø§ØºØ· Ù¢. Ø¥ÙŠÙ‚Ø§Ù Ø·Ø§Ø±Ø¦ ØªÙ„Ù‚Ø§Ø¦ÙŠ."),
        ("2025-06-30 10:58", "âš ï¸", "Ø´Ø°ÙˆØ° ØªØ¯ÙÙ‚ Ø¹Ù†Ø¯ Ù…Ø¶Ø®Ø© Ù¡. ØªÙ… Ø¥Ø®Ø·Ø§Ø± Ø§Ù„Ù…Ø´ØºÙ„."),
        ("2025-06-30 10:50", "â„¹ï¸", "Ø§Ø±ØªÙØ§Ø¹ Ø§Ù„Ø­Ø±Ø§Ø±Ø© Ø¨Ø§Ù„Ù…ÙØ§Ø¹Ù„. Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø¶Ù…Ù† Ø§Ù„Ø­Ø¯ÙˆØ¯ Ø§Ù„Ø¢Ù…Ù†Ø©.")
    ]
    for t, icon, desc in timeline_steps:
        st.markdown(
            f"""<div class="timeline-step"><span class="timeline-icon">{icon}</span>
            <b>{t}</b><br>
            <span style="font-size:1.07em">{desc}</span></div>""",
            unsafe_allow_html=True
        )

elif section == T["side_sections"][12]:  # Energy Optimization
    show_logo()
    st.markdown(f'<div class="{"gradient-ar" if rtl else "gradient-header"}">{T["side_sections"][12]}</div>', unsafe_allow_html=True)
    st.markdown(rtl_wrap("Monitor and optimize plant energy use. AI recommendations below." if lang=="en" else "Ø±Ø§Ù‚Ø¨ ÙˆØ­Ø³Ù† Ø§Ø³ØªÙ‡Ù„Ø§Ùƒ Ø§Ù„Ø·Ø§Ù‚Ø©. ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø¨Ø§Ù„Ø£Ø³ÙÙ„."))
    energy_sect = ["Compressor", "Pump", "Lighting", "Other"] if lang=="en" else ["Ø¶Ø§ØºØ·", "Ù…Ø¶Ø®Ø©", "Ø¥Ø¶Ø§Ø¡Ø©", "Ø£Ø®Ø±Ù‰"]
    vals = [51, 28, 9, 12]
    fig = px.bar(x=energy_sect, y=vals, color=energy_sect, color_discrete_sequence=px.colors.sequential.Plasma)
    fig.update_layout(height=230, margin=dict(l=10, r=10, t=10, b=10), showlegend=False)
    st.plotly_chart(fig, use_container_width=True)
    energy_recos = [
        ("Reduce compressor load during peak hours", "âš¡"),
        ("Schedule maintenance for low demand windows", "ğŸ› ï¸")
    ] if lang == "en" else [
        ("ØªØ®ÙÙŠØ¶ ØªØ´ØºÙŠÙ„ Ø§Ù„Ø¶ÙˆØ§ØºØ· Ø£ÙˆÙ‚Ø§Øª Ø§Ù„Ø°Ø±ÙˆØ©", "âš¡"),
        ("Ø¬Ø¯ÙˆÙ„Ø© Ø§Ù„ØµÙŠØ§Ù†Ø© Ø£ÙˆÙ‚Ø§Øª Ø§Ù„Ø·Ù„Ø¨ Ø§Ù„Ù…Ù†Ø®ÙØ¶", "ğŸ› ï¸")
    ]
    for txt, icon in energy_recos:
        st.markdown(f"""<div class="peak-card" style="background:#e0eafc;margin-bottom:0.6em;">
            <span class="timeline-icon">{icon}</span> {txt}
        </div>""", unsafe_allow_html=True)

elif section == T["side_sections"][13]:  # Future Insights
    show_logo()
    st.markdown(f'<div class="{"gradient-ar" if rtl else "gradient-header"}">{T["side_sections"][13]}</div>', unsafe_allow_html=True)
    st.markdown("<div style=\'display:flex;gap:1.3em;flex-wrap:wrap;\'>", unsafe_allow_html=True)
    future_cards = [
        ("Predictive Risk Alert", "AI models forecast a risk spike for methane at Compressor 2 next week.", "ğŸš¨"),
        ("Efficiency Opportunity", "Upgrade control logic to boost plant efficiency by 3%.", "ğŸŒ±")
    ] if lang == "en" else [
        ("ØªÙ†Ø¨ÙŠÙ‡ Ù…Ø®Ø§Ø·Ø± ØªÙ†Ø¨Ø¤ÙŠ", "ÙŠØªÙˆÙ‚Ø¹ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø§Ø±ØªÙØ§Ø¹ Ø§Ù„Ù…ÙŠØ«Ø§Ù† Ø¹Ù†Ø¯ Ø§Ù„Ø¶Ø§ØºØ· Ù¢ Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ Ø§Ù„Ù‚Ø§Ø¯Ù….", "ğŸš¨"),
        ("ÙØ±ØµØ© ÙƒÙØ§Ø¡Ø©", "ØªØ­Ø¯ÙŠØ« Ù…Ù†Ø·Ù‚ Ø§Ù„ØªØ­ÙƒÙ… Ù„Ø±ÙØ¹ Ø§Ù„ÙƒÙØ§Ø¡Ø© Ù£Ùª.", "ğŸŒ±")
    ]
    for title, desc, icon in future_cards:
        st.markdown(f"""<div class="peak-card" style="min-width:220px;max-width:330px;">
            <span style="font-size:2.1em;">{icon}</span><br>
            <b>{title}</b><br>
            <span style="font-size:1.09em">{desc}</span>
        </div>""", unsafe_allow_html=True)
    x = [datetime.now() + timedelta(days=i) for i in range(7)]
    y = [1.2,1.5,2.0,2.8,3.6,3.9,4.8]
    fig = go.Figure()
    fig.add_trace(go.Scatter(x=x, y=y, mode="lines+markers", line=dict(color="#fa709a", width=3), name="Methane Risk"))
    fig.update_layout(height=200, margin=dict(l=10, r=10, t=10, b=10), title=("Methane Risk Forecast" if lang=="en" else "ØªÙˆÙ‚Ø¹ Ù…Ø®Ø§Ø·Ø± Ø§Ù„Ù…ÙŠØ«Ø§Ù†"))
    st.plotly_chart(fig, use_container_width=True)
    st.markdown("</div>", unsafe_allow_html=True)

elif section == T["side_sections"][14]:  # Operator Feedback
    show_logo()
    st.markdown(f'<div class="{"gradient-ar" if rtl else "gradient-header"}">{T["side_sections"][14]}</div>', unsafe_allow_html=True)
    if "feedback_list" not in st.session_state:
        st.session_state["feedback_list"] = []
    feedback = st.text_area(rtl_wrap("Add operator feedback or incident note:" if lang=="en" else "Ø£Ø¶Ù Ù…Ù„Ø§Ø­Ø¸Ø© Ø£Ùˆ Ù…Ù„Ø§Ø­Ø¸Ø© Ø­Ø§Ø¯Ø« Ù„Ù„Ù…Ø´ØºÙ„:"), key="feedbackbox")
    if st.button("Submit Feedback" if lang=="en" else "Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø©"):
        if feedback.strip():
            st.session_state["feedback_list"].append((datetime.now().strftime("%Y-%m-%d %H:%M"), feedback.strip()))
    for t, fb in reversed(st.session_state["feedback_list"]):
        st.info(rtl_wrap(f"**[{t}]** {fb}"))

elif section == T["side_sections"][15]:  # About
    show_logo()
    st.markdown(f'<div class="{"gradient-ar" if rtl else "gradient-header"}">{T["about_header"]}</div>', unsafe_allow_html=True)
    st.markdown(f"<div class=\'about-bgcard\'>", unsafe_allow_html=True)
    st.markdown(
        "".join([
            f"<span class=\'about-color\' style=\'background:{color}30;color:{color}\'>{value}</span> "
            for color, value in T["about_colorful"]
        ]), unsafe_allow_html=True
    )
    st.markdown(f"<div class=\'about-story\'>{rtl_wrap(T[\'about_story\'])}</div>", unsafe_allow_html=True)
    st.markdown(rtl_wrap("<div class=\'about-feature\'>Features</div>") if lang=="en" else rtl_wrap("<div class=\'about-feature\'>Ø§Ù„Ù…ÙŠØ²Ø§Øª</div>"), unsafe_allow_html=True)
    st.markdown("<ul>"+"".join([f"<li>{f}</li>" for f in T["features"]])+"</ul>", unsafe_allow_html=True)
    st.markdown(rtl_wrap("<div class=\'about-feature\'>How to extend</div>") if lang=="en" else rtl_wrap("<div class=\'about-feature\'>ÙƒÙŠÙÙŠØ© Ø§Ù„ØªÙˆØ³ÙŠØ¹</div>"), unsafe_allow_html=True)
    st.markdown("<ul>"+"".join([f"<li>{f}</li>" for f in T["howto_extend"]])+"</ul>", unsafe_allow_html=True)
    st.markdown(rtl_wrap("<div class=\'about-contact\'><b>Contact</b></div>") if lang=="en" else rtl_wrap("<div class=\'about-contact\'><b>ØªÙˆØ§ØµÙ„ Ù…Ø¹Ù†Ø§</b></div>"), unsafe_allow_html=True)
    for name, mail, phone in T["developers"]:
        st.markdown(f"{T[\'contact\']}: {name}<br>Email: <a href=\'mailto:{mail}\'>{mail}</a><br>Phone: {phone}<br>", unsafe_allow_html=True)
    st.markdown(rtl_wrap(f"<i>{T[\'demo_note\']}</i>"), unsafe_allow_html=True)
    st.markdown("</div>", unsafe_allow_html=True)
