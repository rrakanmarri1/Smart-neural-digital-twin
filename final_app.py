import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
import os
from datetime import datetime, timedelta
import threading
import paho.mqtt.client as mqtt

# Try OpenAI import, handle missing gracefully
try:
    import openai
    openai_available = True
except ImportError:
    openai_available = False

try:
    from twilio.rest import Client
    twilio_available = True
except ImportError:
    twilio_available = False

# ----- LOGO SVG -----
logo_svg = """
<svg width="64" height="64" viewBox="0 0 64 64" fill="none">
  <circle cx="32" cy="32" r="32" fill="url(#grad1)"/>
  <defs>
    <linearGradient id="grad1" x1="0" y1="0" x2="64" y2="64" gradientUnits="userSpaceOnUse">
      <stop stop-color="#43cea2"/>
      <stop offset="1" stop-color="#185a9d"/>
    </linearGradient>
  </defs>
  <g>
    <ellipse cx="32" cy="32" rx="22" ry="10" fill="#fff" fill-opacity="0.18"/>
    <ellipse cx="32" cy="32" rx="12" ry="22" fill="#fff" fill-opacity="0.10"/>
    <path d="M20 32a12 12 0 1 0 24 0 12 12 0 1 0 -24 0" fill="#fff" fill-opacity="0.7"/>
    <path d="M32 16v32M16 32h32" stroke="#185a9d" stroke-width="2" stroke-linecap="round"/>
    <circle cx="32" cy="32" r="6" fill="#43cea2" stroke="#185a9d" stroke-width="2"/>
  </g>
</svg>
"""

# MQTT Config
MQTT_BROKER = "test.mosquitto.org"
MQTT_PORT = 1883
MQTT_TOPIC = "digitaltwin/test/temperature"

# Secure config via environment
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")
TWILIO_SID = os.environ.get("TWILIO_SID")
TWILIO_AUTH = os.environ.get("TWILIO_AUTH")
TWILIO_FROM = os.environ.get("TWILIO_FROM")
TWILIO_TO = os.environ.get("TWILIO_TO")

# App state initialization
for key, default in [
    ("lang", "en"), ("scenario_step", 0), ("solution_idx", 0), ("theme", "dark"),
    ("mqtt_temp", None), ("mqtt_last", None), ("mqtt_started", False), ("sms_sent", False),
    ("feedback_list", [])
]:
    if key not in st.session_state:
        st.session_state[key] = default

# MQTT background thread
def on_connect(client, userdata, flags, rc):
    client.subscribe(MQTT_TOPIC)
def on_message(client, userdata, msg):
    try:
        val = float(msg.payload.decode())
        st.session_state["mqtt_temp"] = val
        st.session_state["mqtt_last"] = datetime.now()
    except Exception:
        pass
def mqtt_thread():
    client = mqtt.Client()
    client.on_connect = on_connect
    client.on_message = on_message
    try:
        client.connect(MQTT_BROKER, MQTT_PORT, 60)
        client.loop_forever()
    except Exception:
        pass
if not st.session_state["mqtt_started"]:
    t = threading.Thread(target=mqtt_thread, daemon=True)
    t.start()
    st.session_state["mqtt_started"] = True

# OpenAI setup
if openai_available and OPENAI_API_KEY:
    openai.api_key = OPENAI_API_KEY

def ask_llm_advanced(prompt, lang, context=None, root_cause=None):
    """
    Enhanced AI Copilot: Now supports context, root cause analysis, and structured outputs.
    Uses OpenAI API v1+.
    """
    if not openai_available or not OPENAI_API_KEY:
        return "LLM Error: OpenAI API not installed or API key not set."

    system_en = f"""You are an expert AI assistant for an industrial digital twin platform called 'Smart Neural Digital Twin'.
You have access to real-time plant data and advanced analytics. Your core capabilities include:
- Answering operational, troubleshooting, and data analysis questions.
- Performing root cause analysis: if a user asks "why" or "root cause", analyze past incidents and suggest a probable root.
- Giving actionable recommendations based on the plant's digital twin data, scenario playback, and forecast.
- Summarizing plant KPIs, risk factors, and energy optimization opportunities.
- If 'context' is provided, summarize and use it.
- If 'root_cause' is provided, use it to explain system failures or propose mitigations.

If asked about specific values, refer to the latest in-memory data if available. Reply in clear, concise, and helpful language.
"""
    system_ar = f"""Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒØ§Ø¡ ØµÙ†Ø§Ø¹ÙŠ Ø®Ø¨ÙŠØ± Ù„Ù…Ù†ØµØ© Ø§Ù„ØªÙˆØ£Ù… Ø§Ù„Ø±Ù‚Ù…ÙŠ Ø§Ù„ØµÙ†Ø§Ø¹ÙŠ Ø§Ù„Ù…Ø³Ù…Ø§Ø© 'Ø§Ù„ØªÙˆØ£Ù… Ø§Ù„Ø±Ù‚Ù…ÙŠ Ø§Ù„Ø¹ØµØ¨ÙŠ Ø§Ù„Ø°ÙƒÙŠ'.
Ù„Ø¯ÙŠÙƒ Ø¥Ù…ÙƒØ§Ù†ÙŠØ© Ø§Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØµÙ†Ø¹ Ø§Ù„Ø­ÙŠØ© ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©. Ù‚Ø¯Ø±Ø§ØªÙƒ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©:
- Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù† Ø£Ø³Ø¦Ù„Ø© Ø§Ù„ØªØ´ØºÙŠÙ„ ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„ ÙˆØ­Ù„ Ø§Ù„Ù…Ø´ÙƒÙ„Ø§Øª.
- ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ø¨Ø¨ Ø§Ù„Ø¬Ø°Ø±ÙŠ: Ø¥Ø°Ø§ Ø³Ø£Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… "Ù„Ù…Ø§Ø°Ø§" Ø£Ùˆ "Ø§Ù„Ø³Ø¨Ø¨ Ø§Ù„Ø¬Ø°Ø±ÙŠ"ØŒ Ù‚Ù… Ø¨ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø­ÙˆØ§Ø¯Ø« ÙˆØ§Ù‚ØªØ±Ø­ Ø§Ù„Ø³Ø¨Ø¨ Ø§Ù„Ù…Ù…ÙƒÙ†.
- Ø¥Ø¹Ø·Ø§Ø¡ ØªÙˆØµÙŠØ§Øª Ø¹Ù…Ù„ÙŠØ© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªÙˆØ£Ù… Ø§Ù„Ø±Ù‚Ù…ÙŠ ÙˆØªØ´ØºÙŠÙ„ Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ ÙˆØ§Ù„ØªÙˆÙ‚Ø¹Ø§Øª.
- ØªÙ„Ø®ÙŠØµ Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡ØŒ Ø¹ÙˆØ§Ù…Ù„ Ø§Ù„Ù…Ø®Ø§Ø·Ø±ØŒ ÙˆÙØ±Øµ ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø·Ø§Ù‚Ø©.
- Ø¥Ø°Ø§ ØªÙ… ØªÙˆÙÙŠØ± 'context'ØŒ Ù„Ø®ØµÙ‡ ÙˆØ§Ø³ØªØ®Ø¯Ù…Ù‡.
- Ø¥Ø°Ø§ ØªÙ… ØªÙˆÙÙŠØ± 'root_cause'ØŒ ÙØ§Ø´Ø±Ø­ Ø¨Ù‡ Ø£Ø³Ø¨Ø§Ø¨ Ø§Ù„Ø£Ø¹Ø·Ø§Ù„ Ø£Ùˆ Ø·Ø±Ù‚ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©.

Ø¥Ø°Ø§ Ø³ÙØ¦Ù„Øª Ø¹Ù† Ù‚ÙŠÙ… Ù…Ø¹ÙŠÙ†Ø©ØŒ Ø§Ø³ØªÙ†Ø¯ Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø­Ø¯Ø« Ø§Ù„Ù…ØªÙˆÙØ±Ø© Ø¨Ø§Ù„Ø°Ø§ÙƒØ±Ø©. Ø£Ø¬Ø¨ Ø¨ÙˆØ¶ÙˆØ­ ÙˆØ§Ø­ØªØ±Ø§ÙÙŠØ©.
"""
    system = system_en if lang == "en" else system_ar

    messages = [{"role": "system", "content": system}]
    if context:
        messages.append({"role": "system", "content": f"context: {context}"})
    if root_cause:
        messages.append({"role": "system", "content": f"root_cause: {root_cause}"})
    messages.append({"role": "user", "content": prompt})

    # OpenAI 1.x+ Chat API (new)
    try:
        resp = openai.chat.completions.create(
            model="gpt-4",
            messages=messages,
            temperature=0.3,
            max_tokens=500,
        )
        return resp.choices[0].message.content
    except Exception as e:
        return "LLM Error: "+str(e)

# Twilio SMS
def send_sms(to, message):
    if not twilio_available:
        return False, "Twilio not installed."
    try:
        if not all([TWILIO_SID, TWILIO_AUTH, TWILIO_FROM, to]):
            return False, "Twilio credentials or phone numbers not set."
        client = Client(TWILIO_SID, TWILIO_AUTH)
        message = client.messages.create(
            body=message,
            from_=TWILIO_FROM,
            to=to
        )
        return True, "Sent."
    except Exception as e:
        return False, str(e)

def to_arabic_numerals(num):
    return str(num).translate(str.maketrans("0123456789", "Ù Ù¡Ù¢Ù£Ù¤Ù¥Ù¦Ù§Ù¨Ù©"))
def rtl_wrap(txt):
    if st.session_state["lang"] == "ar":
        return f'<div style="direction:rtl;text-align:right">{txt}</div>'
    else:
        return f'<div style="direction:ltr;text-align:left">{txt}</div>'
def show_logo():
    st.markdown(f'<div style="text-align:center;padding-bottom:1.2em;">{logo_svg}</div>', unsafe_allow_html=True)

def highlight_metric(val, threshold, color="#fa709a"):
    style = ""
    if val >= threshold:
        style = f"background:{color}22;border-radius:12px;padding:0.1em 0.4em;"
    return style

# Colorful palette
colorful_palette = [
    "#43cea2", "#fa709a", "#ffb347", "#8fd3f4", "#185a9d",
    "#ffe259", "#ffa751", "#fdc830", "#eecda3", "#e0eafc", "#cfdef3", "#fe8c00", "#f83600"
]

# Translations (All sections, all labels, all solutions, all features, all about, complete)
texts = {
    "en": {
        "app_title": "Smart Neural Digital Twin",
        "app_sub": "Intelligent Digital Plant Platform",
        "side_sections": [
            "Digital Twin", "Advanced Dashboard", "Predictive Analytics", "Scenario Playback",
            "Alerts & Fault Log", "Smart Solutions", "KPI Wall", "Plant Heatmap", "Root Cause Explorer", "AI Copilot Chat",
            "Live Plant 3D", "Incident Timeline", "Energy Optimization", "Future Insights", "Operator Feedback", "About"
        ],
        "lang_en": "English",
        "lang_ar": "Arabic",
        "solution_btn": "Next Solution",
        "logo_alt": "Smart Neural Digital Twin Logo",
        "about_header": "Our Story",
        "about_story": """Our journey began with a simple question: <b>How can we detect gas leaks before they become disasters?</b> <span style="color:#fa709a;font-weight:bold">We tried every solution, even innovated with drones, and it worked.</span> But we wanted more: a <b>digital twin that thinks and learns like an engineer, not just a dashboard</b>. We built a platform that brings together <span style="color:#43cea2;font-weight:bold">AI</span>, real-time sensors, and <span style="color:#ffb347;font-weight:bold">predictive analytics</span> to <b>empower every operator to prevent incidents, save costs, and optimize performance</b>. That's our storyâ€”and it's just beginning.""",
        "about_colorful": [
            ("#43cea2", "AI at the Core"),
            ("#fa709a", "Real-time Sensing"),
            ("#ffb347", "Predictive Analytics"),
            ("#8fd3f4", "Instant Actions"),
            ("#185a9d", "Peace of Mind"),
            ("#ffe259", "Smart Monitoring"),
            ("#ffa751", "Safety First"),
        ],
        "features": [
            "Interactive plant schematic & overlays",
            "Advanced dashboards & KPIs",
            "AI-driven fault detection & smart solutions",
            "Root-cause explorer & scenario playback",
            "Live 3D plant visualization",
            "Bilingual support & vibrant design"
        ],
        "howto_extend": [
            "Connect to real plant historian data",
            "Add custom plant schematics & overlays",
            "Integrate with control and alerting systems",
            "Deploy on secure internal networks"
        ],
        "developers": [
            ("Rakan Almarri", "rakan.almarri.2@aramco.com", "0532559664"),
            ("Abdulrahman Alzahrani", "abdulrahman.alzhrani.2@aramco.com", "0549202574")
        ],
        "contact": "Contact Info",
        "demo_note": "Demo use only: Not for live plant operation",
        "live3d_header": "Live Plant 3D",
        "live3d_intro": "Explore the interactive 3D model below. Use your mouse to zoom, rotate, and explore the plant!",
        "live3d_404": "The 3D model failed to load. View the static 3D plant image below.",
        "static_3d_caption": "Sample Plant 3D Visual",
        "ai_explain_btn": "Explain with AI",
        "ai_rootcause_btn": "Root Cause Analysis",
        "ai_whatif_btn": "What-if Scenario",
        "ai_kpi_btn": "Analyze KPIs",
        "ai_energy_btn": "Energy Optimization Advice",
        "ai_feedback_btn": "Summarize Feedback",
        "solutions": [
            {
                "title": "Automated Methane Leak Response",
                "desc": "Integrate advanced sensors with automated shutdown logic to instantly contain future methane leaks.",
                "steps": ["Deploy new IoT sensors", "Implement AI detection", "Link to emergency shutdown", "Train operators"],
                "priority": "High", "effectiveness": "High", "time": "3 days", "cost": "$4,000", "savings": "$25,000/year",
                "icon": "ğŸ›¡ï¸"
            },
            {
                "title": "Pump Predictive Maintenance",
                "desc": "Monitor vibration and temperature to predict pump failures before they occur.",
                "steps": ["Install vibration sensors", "Run ML models", "Alert on anomaly", "Schedule just-in-time maintenance"],
                "priority": "Medium", "effectiveness": "High", "time": "1 week", "cost": "$5,000", "savings": "$18,000/year",
                "icon": "ğŸ”§"
            },
            {
                "title": "Energy Use Optimization",
                "desc": "AI analyzes compressor schedule to cut energy waste by 11%.",
                "steps": ["Analyze compressor cycles", "Optimize schedule", "Implement load shifting", "Track savings"],
                "priority": "High", "effectiveness": "Medium", "time": "2 weeks", "cost": "$6,000", "savings": "$32,000/year",
                "icon": "âš¡"
            },
        ]
    },
    "ar": {
        "app_title": "Ø§Ù„ØªÙˆØ£Ù… Ø§Ù„Ø±Ù‚Ù…ÙŠ Ø§Ù„Ø¹ØµØ¨ÙŠ Ø§Ù„Ø°ÙƒÙŠ",
        "app_sub": "Ù…Ù†ØµØ© Ø§Ù„Ù…ØµÙ†Ø¹ Ø§Ù„Ø°ÙƒÙŠ Ø§Ù„Ø±Ù‚Ù…ÙŠ",
        "side_sections": [
            "Ø§Ù„ØªÙˆØ£Ù… Ø§Ù„Ø±Ù‚Ù…ÙŠ", "Ù„ÙˆØ­Ø© Ø§Ù„Ù‚ÙŠØ§Ø¯Ø© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©", "Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„ØªÙ†Ø¨Ø¤ÙŠØ©", "ØªØ´ØºÙŠÙ„ Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ",
            "Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª ÙˆØ³Ø¬Ù„ Ø§Ù„Ø£Ø¹Ø·Ø§Ù„", "Ø§Ù„Ø­Ù„ÙˆÙ„ Ø§Ù„Ø°ÙƒÙŠØ©", "Ø¬Ø¯Ø§Ø± Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª", "Ø®Ø±ÙŠØ·Ø© Ø­Ø±Ø§Ø±Ø© Ø§Ù„Ù…ØµÙ†Ø¹", "Ù…Ø³ØªÙƒØ´Ù Ø§Ù„Ø³Ø¨Ø¨ Ø§Ù„Ø¬Ø°Ø±ÙŠ",
            "Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„ØµÙ†Ø§Ø¹ÙŠ", "Ù…ØµÙ†Ø¹ Ø«Ù„Ø§Ø«ÙŠ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯", "Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø­ÙˆØ§Ø¯Ø«", "ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø·Ø§Ù‚Ø©", "Ø±Ø¤Ù‰ Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠØ©", "Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ø§Ù„Ù…Ø´ØºÙ„", "Ø­ÙˆÙ„"
        ],
        "lang_en": "Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©",
        "lang_ar": "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©",
        "solution_btn": "Ø§Ù„Ø­Ù„ Ø§Ù„ØªØ§Ù„ÙŠ",
        "logo_alt": "Ø´Ø¹Ø§Ø± Ø§Ù„ØªÙˆØ£Ù… Ø§Ù„Ø±Ù‚Ù…ÙŠ Ø§Ù„Ø¹ØµØ¨ÙŠ Ø§Ù„Ø°ÙƒÙŠ",
        "about_header": "Ù‚ØµØªÙ†Ø§",
        "about_story": """Ø¨Ø¯Ø£Ù†Ø§ Ø±Ø­Ù„ØªÙ†Ø§ Ù…Ù† Ø³Ø¤Ø§Ù„ Ø¨Ø³ÙŠØ·: <b>ÙƒÙŠÙ Ù†ÙƒØ´Ù ØªØ³Ø±Ø¨ Ø§Ù„ØºØ§Ø² Ù‚Ø¨Ù„ Ø£Ù† ÙŠØªØ­ÙˆÙ„ Ø¥Ù„Ù‰ ÙƒØ§Ø±Ø«Ø©ØŸ</b> <span style="color:#fa709a;font-weight:bold">Ø¬Ø±Ø¨Ù†Ø§ ÙƒÙ„ Ø§Ù„Ø­Ù„ÙˆÙ„ ÙˆØ§Ø¨ØªÙƒØ±Ù†Ø§ Ø­ØªÙ‰ Ø§Ù„Ø·Ø§Ø¦Ø±Ø§Øª Ø¨Ø¯ÙˆÙ† Ø·ÙŠØ§Ø± ÙˆÙ†Ø¬Ø­ Ø§Ù„Ø£Ù…Ø±.</span> Ù„ÙƒÙ† Ø£Ø±Ø¯Ù†Ø§ Ø§Ù„Ù…Ø²ÙŠØ¯: <b>ØªÙˆØ£Ù… Ø±Ù‚Ù…ÙŠ ÙŠÙÙƒØ± ÙˆÙŠØªØ¹Ù„Ù… ÙƒÙ…Ù‡Ù†Ø¯Ø³ØŒ Ù„ÙŠØ³ Ù…Ø¬Ø±Ø¯ Ù„ÙˆØ­Ø© Ø¨ÙŠØ§Ù†Ø§Øª</b>. Ø¨Ù†ÙŠÙ†Ø§ Ù…Ù†ØµØ© ØªØ¬Ù…Ø¹ Ø¨ÙŠÙ† <span style="color:#43cea2;font-weight:bold">Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ</span>ØŒ Ø§Ù„Ø­Ø³Ø§Ø³Ø§Øª Ø§Ù„Ù„Ø­Ø¸ÙŠØ©ØŒ Ùˆ<span style="color:#ffb347;font-weight:bold">ØªØ­Ù„ÙŠÙ„Ø§Øª ØªÙ†Ø¨Ø¤ÙŠØ©</span> <b>Ù„ØªÙ…ÙƒÙŠÙ† ÙƒÙ„ Ù…Ø´ØºÙ„ Ù…Ù† Ù…Ù†Ø¹ Ø§Ù„Ø­ÙˆØ§Ø¯Ø«ØŒ ÙˆØªÙˆÙÙŠØ± Ø§Ù„ØªÙƒØ§Ù„ÙŠÙØŒ ÙˆØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡</b>. Ù‡Ø°Ù‡ Ù‚ØµØªÙ†Ø§â€”ÙˆÙ„Ø§ ØªØ²Ø§Ù„ ÙÙŠ Ø¨Ø¯Ø§ÙŠØªÙ‡Ø§.""",
        "about_colorful": [
            ("#43cea2", "Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙÙŠ Ø§Ù„Ù‚Ù„Ø¨"),
            ("#fa709a", "Ø§Ø³ØªØ´Ø¹Ø§Ø± Ù„Ø­Ø¸ÙŠ"),
            ("#ffb347", "ØªØ­Ù„ÙŠÙ„Ø§Øª ØªÙ†Ø¨Ø¤ÙŠØ©"),
            ("#8fd3f4", "Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª ÙÙˆØ±ÙŠØ©"),
            ("#185a9d", "Ø±Ø§Ø­Ø© Ø§Ù„Ø¨Ø§Ù„"),
            ("#ffe259", "Ù…Ø±Ø§Ù‚Ø¨Ø© Ø°ÙƒÙŠØ©"),
            ("#ffa751", "Ø§Ù„Ø³Ù„Ø§Ù…Ø© Ø£ÙˆÙ„Ø§Ù‹"),
        ],
        "features": [
            "Ù…Ø®Ø·Ø· Ù…ØµÙ†Ø¹ ØªÙØ§Ø¹Ù„ÙŠ ÙˆØªØ±Ø§ÙƒØ¨ Ù…Ø¨Ø§Ø´Ø±",
            "Ù„ÙˆØ­Ø§Øª ÙˆÙ…Ø¤Ø´Ø±Ø§Øª Ù…ØªÙ‚Ø¯Ù…Ø©",
            "ÙƒØ´Ù Ø£Ø¹Ø·Ø§Ù„ Ø°ÙƒÙŠ ÙˆØ­Ù„ÙˆÙ„ ÙÙˆØ±ÙŠØ©",
            "Ù…Ø³ØªÙƒØ´Ù Ø§Ù„Ø³Ø¨Ø¨ Ø§Ù„Ø¬Ø°Ø±ÙŠ ÙˆØªØ´ØºÙŠÙ„ Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆÙ‡Ø§Øª",
            "Ø±Ø¤ÙŠØ© Ø«Ù„Ø§Ø«ÙŠØ© Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ù„Ù„Ù…ØµÙ†Ø¹",
            "Ø¯Ø¹Ù… Ù„ØºØªÙŠÙ† ÙˆØªØµÙ…ÙŠÙ… Ø­ÙŠÙˆÙŠ"
        ],
        "howto_extend": [
            "Ø±Ø¨Ø· Ù…Ø¹ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØµÙ†Ø¹ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ©",
            "Ø¥Ø¶Ø§ÙØ© Ù…Ø®Ø·Ø·Ø§Øª ÙˆØªØ±Ø§ÙƒØ¨ Ù…Ø®ØµØµ",
            "Ø¯Ù…Ø¬ Ù…Ø¹ Ø£Ù†Ø¸Ù…Ø© Ø§Ù„ØªØ­ÙƒÙ… ÙˆØ§Ù„ØªÙ†Ø¨ÙŠÙ‡",
            "ØªØ´ØºÙŠÙ„ Ø¯Ø§Ø®Ù„ÙŠ Ø¢Ù…Ù†"
        ],
        "developers": [
            ("Ø±Ø§ÙƒØ§Ù† Ø§Ù„Ù…Ø¹Ø§Ø±ÙŠ", "rakan.almarri.2@aramco.com", "0532559664"),
            ("Ø¹Ø¨Ø¯Ø§Ù„Ø±Ø­Ù…Ù† Ø§Ù„Ø²Ù‡Ø±Ø§Ù†ÙŠ", "abdulrahman.alzhrani.2@aramco.com", "0549202574")
        ],
        "contact": "Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªÙˆØ§ØµÙ„",
        "demo_note": "Ù„Ù„Ø¹Ø±Ø¶ ÙÙ‚Ø·: ØºÙŠØ± Ù…Ø®ØµØµ Ù„Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„ÙØ¹Ù„ÙŠ",
        "live3d_header": "Ù…ØµÙ†Ø¹ Ø«Ù„Ø§Ø«ÙŠ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ù…Ø¨Ø§Ø´Ø±",
        "live3d_intro": "ØªÙØ§Ø¹Ù„ Ù…Ø¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø«Ù„Ø§Ø«ÙŠ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ø£Ø¯Ù†Ø§Ù‡. Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…Ø§ÙˆØ³ Ù„Ù„ØªØ­Ø±ÙŠÙƒ ÙˆØ§Ù„ØªÙƒØ¨ÙŠØ±.",
        "live3d_404": "ØªØ¹Ø°Ø± ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ØŒ Ø´Ø§Ù‡Ø¯ ØµÙˆØ±Ø© Ø§Ù„Ù…ØµÙ†Ø¹ Ø§Ù„Ø«Ù„Ø§Ø«ÙŠ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ø¨Ø§Ù„Ø£Ø³ÙÙ„.",
        "static_3d_caption": "Ù…Ø´Ù‡Ø¯ Ø«Ù„Ø§Ø«ÙŠ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ù„Ù…ØµÙ†Ø¹ ØµÙ†Ø§Ø¹ÙŠ",
        "ai_explain_btn": "Ø´Ø±Ø­ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„ØµÙ†Ø§Ø¹ÙŠ",
        "ai_rootcause_btn": "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ø¨Ø¨ Ø§Ù„Ø¬Ø°Ø±ÙŠ",
        "ai_whatif_btn": "Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ Ø§ÙØªØ±Ø§Ø¶ÙŠ",
        "ai_kpi_btn": "ØªØ­Ù„ÙŠÙ„ Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡",
        "ai_energy_btn": "ØªÙˆØµÙŠØ§Øª ØªÙˆÙÙŠØ± Ø§Ù„Ø·Ø§Ù‚Ø©",
        "ai_feedback_btn": "ØªÙ„Ø®ÙŠØµ Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª",
        "solutions": [
            {
                "title": "Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø¢Ù„ÙŠØ© Ù„ØªØ³Ø±Ø¨ Ø§Ù„Ù…ÙŠØ«Ø§Ù†",
                "desc": "Ø¯Ù…Ø¬ Ø­Ø³Ø§Ø³Ø§Øª Ù…ØªØ·ÙˆØ±Ø© Ù…Ø¹ Ù…Ù†Ø·Ù‚ Ø¥ÙŠÙ‚Ø§Ù ØªÙ„Ù‚Ø§Ø¦ÙŠ Ù„Ø§Ø­ØªÙˆØ§Ø¡ Ø§Ù„ØªØ³Ø±Ø¨Ø§Øª ÙÙˆØ±Ø§Ù‹.",
                "steps": ["ØªØ±ÙƒÙŠØ¨ Ø­Ø³Ø§Ø³Ø§Øª Ø¥Ù†ØªØ±Ù†Øª Ø§Ù„Ø£Ø´ÙŠØ§Ø¡", "ØªÙØ¹ÙŠÙ„ ÙƒØ´Ù Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ", "Ø±Ø¨Ø· Ø¨Ø§Ù„Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø·Ø§Ø±Ø¦", "ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…Ø´ØºÙ„ÙŠÙ†"],
                "priority": "Ø¹Ø§Ù„ÙŠØ©", "effectiveness": "Ø¹Ø§Ù„ÙŠØ©", "time": "Ù£ Ø£ÙŠØ§Ù…", "cost": "$Ù¤Ù¬Ù Ù Ù ", "savings": "$Ù¢Ù¥Ù¬Ù Ù Ù /Ø³Ù†Ø©",
                "icon": "ğŸ›¡ï¸"
            },
            {
                "title": "ØµÙŠØ§Ù†Ø© Ø§Ø³ØªØ¨Ø§Ù‚ÙŠØ© Ù„Ù„Ù…Ø¶Ø®Ø§Øª",
                "desc": "Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø§Ù‡ØªØ²Ø§Ø²Ø§Øª ÙˆØ§Ù„Ø­Ø±Ø§Ø±Ø© Ù„Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ø£Ø¹Ø·Ø§Ù„ Ù‚Ø¨Ù„ ÙˆÙ‚ÙˆØ¹Ù‡Ø§.",
                "steps": ["ØªØ±ÙƒÙŠØ¨ Ø­Ø³Ø§Ø³Ø§Øª Ø§Ù„Ø§Ù‡ØªØ²Ø§Ø²", "ØªØ´ØºÙŠÙ„ Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ", "ØªÙ†Ø¨ÙŠÙ‡ Ø¹Ù†Ø¯ ÙˆØ¬ÙˆØ¯ Ø´Ø°ÙˆØ°", "Ø¬Ø¯ÙˆÙ„Ø© ØµÙŠØ§Ù†Ø© ÙÙˆØ±ÙŠØ©"],
                "priority": "Ù…ØªÙˆØ³Ø·Ø©", "effectiveness": "Ø¹Ø§Ù„ÙŠØ©", "time": "Ø£Ø³Ø¨ÙˆØ¹", "cost": "$Ù¥Ù¬Ù Ù Ù ", "savings": "$Ù¡Ù¨Ù¬Ù Ù Ù /Ø³Ù†Ø©",
                "icon": "ğŸ”§"
            },
            {
                "title": "ØªØ­Ø³ÙŠÙ† Ø§Ø³ØªÙ‡Ù„Ø§Ùƒ Ø§Ù„Ø·Ø§Ù‚Ø©",
                "desc": "ØªØ­Ù„Ù„ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø¶ÙˆØ§ØºØ· Ù„Ø®ÙØ¶ Ø§Ù„Ù‡Ø¯Ø± Ø¨Ù†Ø³Ø¨Ø© Ù¡Ù¡Ùª.",
                "steps": ["ØªØ­Ù„ÙŠÙ„ Ø¯ÙˆØ±Ø§Øª Ø§Ù„Ø¶ÙˆØ§ØºØ·", "ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¬Ø¯ÙˆÙ„Ø©", "ØªØ·Ø¨ÙŠÙ‚ Ù†Ù‚Ù„ Ø§Ù„Ø£Ø­Ù…Ø§Ù„", "Ù…ØªØ§Ø¨Ø¹Ø© Ø§Ù„ØªÙˆÙÙŠØ±"],
                "priority": "Ø¹Ø§Ù„ÙŠØ©", "effectiveness": "Ù…ØªÙˆØ³Ø·Ø©", "time": "Ø£Ø³Ø¨ÙˆØ¹Ø§Ù†", "cost": "$Ù¦Ù¬Ù Ù Ù ", "savings": "$Ù£Ù¢Ù¬Ù Ù Ù /Ø³Ù†Ø©",
                "icon": "âš¡"
            },
        ]
    }
}

# ----- THEME & CSS -----
if st.sidebar.button("ğŸŒ— Theme", key="themebtn"):
    st.session_state["theme"] = "light" if st.session_state["theme"] == "dark" else "dark"

# Custom gradient backgrounds for color and "fun"
light_gradient = "linear-gradient(135deg, #e0eafc 0%, #ffe259 100%)"
dark_gradient = "linear-gradient(135deg, #232526 0%, #185a9d 100%)"

# Enhanced CSS for color, contrast, and fun
st.markdown(f"""
    <style>
    @import url('https://fonts.googleapis.com/css2?family=Cairo:wght@700&family=Montserrat:wght@700&display=swap');
    html, body, [class*="css"] {{
        background: {'#181a2a' if st.session_state["theme"] == "dark" else '#f6f6f7'} !important;
        color: {'#f9fcff' if st.session_state["theme"] == "dark" else '#232526'} !important;
        font-family: 'Montserrat', 'Cairo', sans-serif !important;
    }}
    .peak-card {{
        background: linear-gradient(135deg, #e0eafc 0%, #ffe259 100%);
        border-radius: 18px;
        box-shadow: 0 8px 32px 0 rgba(31,38,135,.18);
        margin-bottom: 1.5em;
        padding: 1.5em 2em;
        animation: peakfade 0.8s;
        border-left: 8px solid #43cea2;
        transition: box-shadow 0.21s, transform 0.18s;
    }}
    .peak-card:hover {{
        box-shadow: 0 12px 38px 0 #fa709a55;
        transform: scale(1.018);
        border-left: 8px solid #fa709a;
    }}
    .kpi-card {{
        background: linear-gradient(135deg, #43cea2 0%, #fa709a 82%, #ffe259 100%);
        border-radius: 13px;
        color: #fff !important;
        font-size: 1.25em;
        font-weight: 700;
        box-shadow: 0 8px 24px 0 rgba(31,38,135,.10);
        padding: 1.3em 1.3em;
        text-align: center;
        margin-bottom: 1em;
        transition: box-shadow 0.18s, transform 0.16s;
        animation: peakfade 0.7s;
    }}
    .kpi-card:hover {{
        box-shadow: 0 8px 36px 0 #ffe25977;
        transform: scale(1.025);
    }}
    .rtl {{
        direction: rtl;
        text-align: right;
        font-family: 'Cairo', sans-serif !important;
    }}
    .ltr {{
        direction: ltr;
        text-align: left;
        font-family: 'Montserrat', sans-serif !important;
    }}
    .sidebar-title {{
        font-size: 2em !important;
        font-weight: 900 !important;
        color: #43cea2 !important;
        letter-spacing: 0.5px;
        margin-bottom: 0.2em !important;
        text-shadow: 0 3px 10px #185a9d22;
    }}
    .sidebar-subtitle {{
        font-size: 1.15em !important;
        color: #fa709a !important;
        margin-bottom: 1em;
        margin-top: -.7em !important;
        text-shadow: 0 1px 6px #ffb34744;
    }}
    .gradient-header, .gradient-ar {{
        font-weight: 900;
        font-size: 2.1em;
        background: linear-gradient(90deg,#43cea2,#fa709a 60%,#ffe259 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        margin-bottom: 0.3em;
        letter-spacing: .5px;
        text-shadow: 0 1px 6px #185a9d1c;
    }}
    .timeline-step {{
        border-left: 4px solid #43cea2;
        margin-left: 0.8em;
        padding-left: 1.2em;
        margin-bottom: 1em;
        position: relative;
        animation: peakfade 0.7s;
    }}
    .timeline-step:before {{
        content: '';
        position: absolute;
        left: -14px;
        top: 0.18em;
        width: 18px;
        height: 18px;
        background: #fa709a;
        border-radius: 100%;
        border: 2px solid #fff;
        box-shadow: 0 0 0 3px #ffe25933;
    }}
    .timeline-icon {{
        font-size: 1.5em;
        margin-right: 0.5em;
        vertical-align: middle;
    }}
    .about-bgcard {{
        background: linear-gradient(140deg,#43cea210,#fa709a10 60%,#ffe25910 100%);
        border-radius: 22px;
        padding: 2.2em 2.1em 1.8em 2.1em;
        margin-top: 1.6em;
        margin-bottom: 2.2em;
        box-shadow: 0 7px 32px 0 #43cea233;
        position: relative;
        animation: peakfade 0.9s;
    }}
    .about-story {{
        font-size: 1.18em;
        font-weight: 600;
        margin-bottom: 2em;
        color: {'#fff' if st.session_state["theme"] == "dark" else '#222'};
        background: none;
        line-height: 1.65em;
        text-shadow: 0 2px 16px #43cea233, 0 1px 2px #fff4;
    }}
    .about-feature {{
        font-weight: 700;
        font-size: 1.16em;
        margin: .45em 0 .14em 0;
    }}
    .about-color {{
        font-weight: 900;
        font-size: 1.20em;
        margin-bottom: .45em;
        display: inline-block;
        padding: .18em .9em;
        border-radius: 12px;
        margin-right: .9em;
        margin-bottom: .5em;
        color: #232526;
        background: #fff;
        box-shadow: 0 2px 8px #185a9d22;
        border: 2px solid #43cea2;
    }}
    .about-color:nth-child(2) {{border-color: #fa709a;}}
    .about-color:nth-child(3) {{border-color: #ffb347;}}
    .about-color:nth-child(4) {{border-color: #8fd3f4;}}
    .about-color:nth-child(5) {{border-color: #185a9d;}}
    .about-color:nth-child(6) {{border-color: #ffe259;}}
    .about-color:nth-child(7) {{border-color: #ffa751;}}
    .about-contact {{
        font-size: 1.13em;
        margin-top: 1.9em;
        margin-bottom: .6em;
    }}
    .ai-action-bar {{
        display: flex;
        gap: 1.1em;
        flex-wrap: wrap;
        margin: 1.3em 0 1em 0;
        justify-content: center;
    }}
    .ai-action-btn {{
        background: linear-gradient(90deg,#43cea2,#fa709a 80%);
        color: #fff;
        border: none;
        border-radius: 8px;
        padding: 0.5em 1.3em;
        font-size: 1.07em;
        font-weight: 700;
        cursor: pointer;
        box-shadow: 0 3px 14px #185a9d23;
        transition: background .19s, box-shadow .13s, transform .12s;
    }}
    .ai-action-btn:hover {{
        background: linear-gradient(90deg,#fa709a 60%,#43cea2 100%);
        box-shadow: 0 8px 28px #fa709a33;
        transform: translateY(-1.5px) scale(1.03);
    }}
    .feedback-bubble {{
        background: #43cea222;
        border-radius: 12px;
        padding: 0.8em 1.1em;
        margin-bottom: 0.7em;
        box-shadow: 0 2px 10px #43cea207;
    }}
    .stButton>button[disabled], .stButton>button:disabled {{
        background: #e0eafc !important;
        color: #bdbdbd !important;
    }}
    @keyframes peakfade {{
        0% {{ opacity: 0; transform: translateY(40px);}}
        100% {{ opacity: 1; transform: translateY(0);}}
    }}
    .stTable, .stDataFrame, .stMarkdown, .stCaption, .stText, .stTextInput, .stTextArea {{
        font-family: 'Montserrat', 'Cairo', sans-serif !important;
    }}
    </style>
""", unsafe_allow_html=True)

# Sidebar
with st.sidebar:
    st.markdown(
        f"""<div class="sidebar-title">{texts[st.session_state["lang"]]["app_title"]}</div>
            <div class="sidebar-subtitle">{texts[st.session_state["lang"]]["app_sub"]}</div>""", unsafe_allow_html=True)
    lang_sel = st.radio(
        "", (texts["en"]["lang_en"], texts["en"]["lang_ar"]) if st.session_state["lang"] == "en" else (texts["ar"]["lang_en"], texts["ar"]["lang_ar"]),
        horizontal=True, index=0 if st.session_state["lang"] == "en" else 1
    )
    st.session_state["lang"] = "en" if lang_sel == texts["en"]["lang_en"] else "ar"
    section_list = texts[st.session_state["lang"]]["side_sections"]
    section = st.radio(" ", section_list, index=0, label_visibility="collapsed")

lang = st.session_state["lang"]
T = texts[lang]
rtl = True if lang == "ar" else False

np.random.seed(1)
demo_df = pd.DataFrame({
    "time": pd.date_range(datetime.now() - timedelta(hours=24), periods=48, freq="30min"),
    "Temperature": np.random.normal(55, 6, 48),
    "Pressure": np.random.normal(7, 1.2, 48),
    "Methane": np.clip(np.random.normal(1.4, 0.7, 48), 0, 6)
})

# ========== MAIN SECTIONS (all elif, all translations, fixed/enhanced) ==========

if section == T["side_sections"][0]:  # Digital Twin (Live MQTT)
    show_logo()
    st.markdown(f'<div class="{"gradient-ar" if rtl else "gradient-header"}">{T["side_sections"][0]}</div>', unsafe_allow_html=True)
    col1, col2 = st.columns([3,2])
    with col1:
        try:
            st.image("realtime_streaming.png", caption=rtl_wrap("MQTT Real-Time Streaming Example" if lang=="en" else "Ù…Ø«Ø§Ù„ Ù…Ø´Ø§Ø±ÙƒØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­ÙŠØ©"))
        except Exception:
            st.image("https://cdn.pixabay.com/photo/2016/11/29/10/07/architecture-1868667_1280.jpg", caption=rtl_wrap("Demo Image"))
    with col2:
        st.markdown(rtl_wrap("Live Temperature (MQTT, topic: digitaltwin/test/temperature)" if lang=="en" else "Ù‚Ø±Ø§Ø¡Ø© Ø¯Ø±Ø¬Ø© Ø§Ù„Ø­Ø±Ø§Ø±Ø© Ø§Ù„Ø­ÙŠØ© (MQTT)"))
        temp = st.session_state["mqtt_temp"]
        if temp is not None:
            display_temp = to_arabic_numerals(round(temp,2)) if lang == "ar" else round(temp,2)
            style = highlight_metric(temp, 60)
            st.markdown(f"<div style='font-size:2.7em;font-weight:900;{style}'>{display_temp} Â°C</div>", unsafe_allow_html=True)
            if temp > 60 and not st.session_state["sms_sent"]:
                ok, msg = send_sms(TWILIO_TO, (f"ALERT: Plant temperature exceeded safe level! Temp={temp:.1f}Â°C" if lang=="en" else f"ØªÙ†Ø¨ÙŠÙ‡: Ø¯Ø±Ø¬Ø© Ø­Ø±Ø§Ø±Ø© Ø§Ù„Ù…ØµÙ†Ø¹ ØªØ¬Ø§ÙˆØ²Øª Ø§Ù„Ø­Ø¯ Ø§Ù„Ù…Ø³Ù…ÙˆØ­! Ø¯Ø±Ø¬Ø© Ø§Ù„Ø­Ø±Ø§Ø±Ø©={temp:.1f}Â°Ù…"))
                st.session_state["sms_sent"] = True
                st.warning("âš ï¸ SMS Alert sent to supervisor!" if lang=="en" else "âš ï¸ ØªÙ… Ø¥Ø±Ø³Ø§Ù„ ØªÙ†Ø¨ÙŠÙ‡ SMS Ù„Ù„Ù…Ø´Ø±Ù!")
        else:
            st.info(rtl_wrap("Waiting for MQTT..." if lang=="en" else "ÙÙŠ Ø§Ù†ØªØ¸Ø§Ø± Ø¨ÙŠØ§Ù†Ø§Øª MQTT..."))
        st.caption(f"{'Last update' if lang=='en' else 'Ø¢Ø®Ø± ØªØ­Ø¯ÙŠØ«'}: {st.session_state['mqtt_last'] if st.session_state['mqtt_last'] else 'N/A'}")

elif section == T["side_sections"][1]:  # Advanced Dashboard
    show_logo()
    st.markdown(f'<div class="{"gradient-ar" if rtl else "gradient-header"}">{T["side_sections"][1]}</div>', unsafe_allow_html=True)
    st.markdown(rtl_wrap("KPIs and live trends for the plant." if lang=="en" else "Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª ÙˆØ§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª Ø§Ù„Ø­ÙŠØ© Ù„Ù„Ù…ØµÙ†Ø¹."))
    fig = px.line(demo_df, x="time", y=["Temperature", "Pressure", "Methane"], labels={"value":"Reading", "variable":"Tag"})
    fig.update_traces(mode="lines+markers")
    fig.update_layout(legend_title_text="Tag", height=350, hovermode="x unified", margin=dict(t=25,b=0))
    st.plotly_chart(fig, use_container_width=True)
    st.markdown('<div class="ai-action-bar">', unsafe_allow_html=True)
    if st.button(T["ai_kpi_btn"], key="ai_kpi_btn"):
        summary = ask_llm_advanced(
            prompt="Summarize recent plant performance and KPIs. Highlight any anomalies or risks. Use the following data:\n"+demo_df.tail(24).to_csv(index=False),
            lang=lang,
            context=f"Recent KPIs: {demo_df.tail(24).to_dict(orient='list')}"
        )
        st.info(rtl_wrap(summary))
    st.markdown('</div>', unsafe_allow_html=True)

elif section == T["side_sections"][2]:  # Predictive Analytics
    show_logo()
    st.markdown(f'<div class="{"gradient-ar" if rtl else "gradient-header"}">{T["side_sections"][2]}</div>', unsafe_allow_html=True)
    st.markdown(rtl_wrap("Forecast of methane and temperature for next 7 days." if lang=="en" else "ØªÙˆÙ‚Ø¹ Ø§Ù„Ù…ÙŠØ«Ø§Ù† ÙˆØ¯Ø±Ø¬Ø© Ø§Ù„Ø­Ø±Ø§Ø±Ø© Ù„Ù„Ø£ÙŠØ§Ù… Ø§Ù„Ø³Ø¨Ø¹Ø© Ø§Ù„Ù‚Ø§Ø¯Ù…Ø©."))
    days = pd.date_range(datetime.now(), periods=7)
    forecast = pd.DataFrame({
        "Day": days,
        "Methane": np.linspace(1.2, 4.5, 7) + np.random.normal(0, 0.2, 7),
        "Temp": np.linspace(55, 63, 7) + np.random.normal(0, 1, 7)
    })
    st.line_chart(forecast.set_index("Day"))
    st.markdown('<div class="ai-action-bar">', unsafe_allow_html=True)
    if st.button(T["ai_whatif_btn"], key="ai_whatif_btn"):
        summary = ask_llm_advanced(
            prompt="If methane rises 20% above the predicted trend, what are the operational risks and what should be done?",
            lang=lang,
            context=f"Forecast: {forecast.to_dict(orient='list')}"
        )
        st.info(rtl_wrap(summary))
    st.markdown('</div>', unsafe_allow_html=True)

elif section == T["side_sections"][3]:  # Scenario Playback
    show_logo()
    st.markdown(f'<div class="{"gradient-ar" if rtl else "gradient-header"}">{T["side_sections"][3]}</div>', unsafe_allow_html=True)
    st.markdown(rtl_wrap("Replay plant incident scenarios hour by hour." if lang=="en" else "ØªØ´ØºÙŠÙ„ Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆÙ‡Ø§Øª Ø§Ù„Ø­ÙˆØ§Ø¯Ø« Ø³Ø§Ø¹Ø© Ø¨Ø³Ø§Ø¹Ø©."))
    step = st.slider(T["side_sections"][3], 0, 23, 0)
    st.markdown(rtl_wrap(f"Scenario at hour {step}" if lang=="en" else f"Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ Ø¹Ù†Ø¯ Ø§Ù„Ø³Ø§Ø¹Ø© {to_arabic_numerals(step)}"))
    chart_data = np.cumsum(np.random.randn(24)) + 50
    st.line_chart(chart_data[:step+1])
    st.markdown('<div class="ai-action-bar">', unsafe_allow_html=True)
    if st.button(T["ai_explain_btn"], key="ai_explain_btn_scenario"):
        summary = ask_llm_advanced(
            prompt=f"Explain what happened in this scenario playback at hour {step}.",
            lang=lang,
            context=f"Scenario time series: {chart_data[:step+1].tolist()}"
        )
        st.info(rtl_wrap(summary))
    st.markdown('</div>', unsafe_allow_html=True)

elif section == T["side_sections"][4]:  # Alerts & Fault Log
    show_logo()
    st.markdown(f'<div class="{"gradient-ar" if rtl else "gradient-header"}">{T["side_sections"][4]}</div>', unsafe_allow_html=True)
    alert_log = pd.DataFrame([
        {"Time":"2025-07-01 05:00","Type":("High Temp" if lang=="en" else "Ø­Ø±Ø§Ø±Ø© Ø¹Ø§Ù„ÙŠØ©"),"Status":("Open" if lang=="en" else "Ù…ÙØªÙˆØ­")},
        {"Time":"2025-07-01 03:32","Type":("Methane Spike" if lang=="en" else "Ø§Ø±ØªÙØ§Ø¹ Ø§Ù„Ù…ÙŠØ«Ø§Ù†"),"Status":("Closed" if lang=="en" else "Ù…ØºÙ„Ù‚")},
        {"Time":"2025-06-30 22:10","Type":("Low Flow" if lang=="en" else "ØªØ¯ÙÙ‚ Ù…Ù†Ø®ÙØ¶"),"Status":("Closed" if lang=="en" else "Ù…ØºÙ„Ù‚")},
    ])
    st.table(alert_log)
    st.markdown('<div class="ai-action-bar">', unsafe_allow_html=True)
    if st.button(T["ai_rootcause_btn"], key="ai_rootcause_btn_alerts"):
        summary = ask_llm_advanced(
            prompt="Analyze the cause of the latest open plant alert and propose mitigation.",
            lang=lang,
            context=f"Alert log: {alert_log.to_dict(orient='records')}",
            root_cause="High temperature, recent methane spike"
        )
        st.info(rtl_wrap(summary))
    st.markdown('</div>', unsafe_allow_html=True)

elif section == T["side_sections"][5]:  # Smart Solutions
    show_logo()
    idx = st.session_state["solution_idx"]
    solutions = T["solutions"]
    sol = solutions[idx]
    steps_html = "".join([f"<li>{s}</li>" for s in sol["steps"]])
    st.markdown(f"""
    <div class="peak-card">
        <div style="font-size:2em;">{sol["icon"]}</div>
        <b style="font-size:1.3em">{sol["title"]}</b>
        <div style="margin:0.8em 0 0.5em 0;">{sol["desc"]}</div>
        <ul style="margin-bottom:0.7em;">{steps_html}</ul>
        <div style="display:flex;gap:0.9em;flex-wrap:wrap;">
            <span style="background:#185a9d12;padding:0.3em 1em;border-radius:6px;">
                {("Priority" if lang=="en" else "Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©")}: {sol["priority"]}
            </span>
            <span style="background:#fa709a15;padding:0.3em 1em;border-radius:6px;">
                {("Effectiveness" if lang=="en" else "Ø§Ù„ÙØ¹Ø§Ù„ÙŠØ©")}: {sol["effectiveness"]}
            </span>
            <span style="background:#ffe25922;padding:0.3em 1em;border-radius:6px;">
                {("Time" if lang=="en" else "Ø§Ù„Ù…Ø¯Ø©")}: {sol["time"]}
            </span>
            <span style="background:#43cea222;padding:0.3em 1em;border-radius:6px;">
                {("Cost" if lang=="en" else "Ø§Ù„ØªÙƒÙ„ÙØ©")}: {sol["cost"]}
            </span>
            <span style="background:#8fd3f433;padding:0.3em 1em;border-radius:6px;">
                {("Savings" if lang=="en" else "Ø§Ù„ØªÙˆÙÙŠØ±")}: {sol["savings"]}
            </span>
        </div>
    </div>
    """, unsafe_allow_html=True)
    if st.button(T["solution_btn"], key=f"solution-next-{idx}"):
        st.session_state["solution_idx"] = (idx + 1) % len(solutions)

elif section == T["side_sections"][6]:  # KPI Wall
    show_logo()
    kpis = [
        ("Overall Efficiency", "âœ…", "#8fd3f4"),
        ("Energy Used (MWh)", "âš¡", "#fe8c00"),
        ("Water Saved (mÂ³)", "ğŸ’§", "#43cea2"),
        ("Incidents This Year", "ğŸ›‘", "#fa709a")
    ] if lang == "en" else [
        ("Ø§Ù„ÙƒÙØ§Ø¡Ø© Ø§Ù„Ø¹Ø§Ù…Ø©", "âœ…", "#8fd3f4"),
        ("Ø§Ù„Ø·Ø§Ù‚Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© (Ù…ÙŠØºØ§ÙˆØ§Ø·)", "âš¡", "#fe8c00"),
        ("Ø§Ù„Ù…Ø§Ø¡ Ø§Ù„Ù…ÙˆÙØ± (Ù…Â³)", "ğŸ’§", "#43cea2"),
        ("Ø§Ù„Ø­ÙˆØ§Ø¯Ø« Ù‡Ø°Ø§ Ø§Ù„Ø¹Ø§Ù…", "ğŸ›‘", "#fa709a")
    ]
    vals = [96, 272, 62, 1]
    goals = [98, 250, 70, 0]
    st.markdown("<div style='display:flex;gap:1.3em;flex-wrap:wrap;'>", unsafe_allow_html=True)
    for i, (name, icon, color) in enumerate(kpis):
        display_val = to_arabic_numerals(vals[i]) if lang == "ar" else str(vals[i])
        display_goal = to_arabic_numerals(goals[i]) if lang == "ar" else str(goals[i])
        kpi_style = ""
        if (lang == "en" and i == 3 and vals[i] > 0) or (lang == "ar" and i == 3 and vals[i] > 0):
            kpi_style = "background:#fa709a33;"
        st.markdown(f"""<div class="kpi-card" style="background:{color}c0;{kpi_style}">
            <span style="font-size:2.1em;">{icon}</span><br>
            <b>{name}</b><br>
            <span style="font-size:2.3em;font-weight:900">{display_val}</span>
            <div style="font-size:.95em;color:#222;">{('Goal' if lang=='en' else 'Ø§Ù„Ù‡Ø¯Ù')}: {display_goal}</div>
        </div>""", unsafe_allow_html=True)
    st.markdown("</div>", unsafe_allow_html=True)

elif section == T["side_sections"][7]:  # Plant Heatmap
    show_logo()
    st.markdown(f'<div class="{"gradient-ar" if rtl else "gradient-header"}">{T["side_sections"][7]}</div>', unsafe_allow_html=True)
    st.markdown(rtl_wrap("High temperature and pressure zones are highlighted below." if lang=="en" else "Ø§Ù„Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ø­Ø±Ø¬Ø© Ù„Ù„Ø­Ø±Ø§Ø±Ø© ÙˆØ§Ù„Ø¶ØºØ· Ù…ÙˆØ¶Ø­Ø© Ø£Ø¯Ù†Ø§Ù‡."))
    z = np.random.uniform(25, 70, (8, 10))
    fig = go.Figure(data=go.Heatmap(z=z, colorscale='YlOrRd', colorbar=dict(title=('Temp Â°C' if lang=='en' else 'Ø­Ø±Ø§Ø±Ø©'))))
    fig.update_layout(height=320, margin=dict(l=12, r=12, t=20, b=20))
    st.plotly_chart(fig, use_container_width=True)
    st.caption(rtl_wrap("Hover to inspect exact zone values." if lang=="en" else "Ù…Ø±Ø± Ø§Ù„ÙØ£Ø±Ø© Ù„Ø±Ø¤ÙŠØ© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø¯Ù‚ÙŠÙ‚Ø©."))

elif section == T["side_sections"][8]:  # Root Cause Explorer
    show_logo()
    st.markdown(f'<div class="{"gradient-ar" if rtl else "gradient-header"}">{T["side_sections"][8]}</div>', unsafe_allow_html=True)
    st.markdown(rtl_wrap("Trace issues to their origin. Sample propagation path shown below." if lang=="en" else "ØªØªØ¨Ø¹ Ø§Ù„Ù…Ø´ÙƒÙ„Ø§Øª Ø¥Ù„Ù‰ Ø£ØµÙ„Ù‡Ø§. Ø³Ù„Ø³Ù„Ø© Ø§Ù„Ø³Ø¨Ø¨ ÙˆØ§Ù„Ù†ØªÙŠØ¬Ø© Ø£Ø¯Ù†Ø§Ù‡."))
    st.markdown("""
    <div style="margin-top:1em;display:flex;justify-content:center;">
    <svg width="340" height="180" viewBox="0 0 340 180">
      <rect x="20" y="70" width="80" height="38" rx="12" fill="#43cea2" opacity="0.89"/>
      <rect x="140" y="30" width="90" height="38" rx="12" fill="#ffb347" opacity="0.91"/>
      <rect x="140" y="110" width="90" height="38" rx="12" fill="#fa709a" opacity="0.91"/>
      <rect x="260" y="70" width="60" height="38" rx="12" fill="#8fd3f4" opacity="0.91"/>
      <text x="60" y="93" font-size="1.2em" fill="#fff" font-family="Cairo,Montserrat" text-anchor="middle">{}</text>
      <text x="185" y="53" font-size="1.1em" fill="#fff" font-family="Cairo,Montserrat" text-anchor="middle">{}</text>
      <text x="185" y="133" font-size="1.1em" fill="#fff" font-family="Cairo,Montserrat" text-anchor="middle">{}</text>
      <text x="290" y="93" font-size="1.1em" fill="#185a9d" font-family="Cairo,Montserrat" text-anchor="middle">{}</text>
      <line x1="100" y1="89" x2="140" y2="49" stroke="#43cea2" stroke-width="3" marker-end="url(#arrow)"/>
      <line x1="100" y1="89" x2="140" y2="129" stroke="#43cea2" stroke-width="3" marker-end="url(#arrow)"/>
      <line x1="230" y1="49" x2="260" y2="89" stroke="#ffb347" stroke-width="3" marker-end="url(#arrow)"/>
      <line x1="230" y1="129" x2="260" y2="89" stroke="#fa709a" stroke-width="3" marker-end="url(#arrow)"/>
      <defs>
        <marker id="arrow" markerWidth="10" markerHeight="10" refX="8" refY="3" orient="auto" markerUnits="strokeWidth">
          <path d="M0,0 L0,6 L9,3 z" fill="#185a9d" />
        </marker>
      </defs>
    </svg>
    </div>
    """.format(
        "Root: Methane leak" if lang=="en" else "Ø§Ù„Ø¬Ø°Ø±: ØªØ³Ø±Ø¨ Ù…ÙŠØ«Ø§Ù†",
        "Compressor 2 Fault" if lang=="en" else "Ø¹Ø·Ù„ Ø§Ù„Ø¶Ø§ØºØ· Ù¢",
        "Pump Overload" if lang=="en" else "ØªØ­Ù…ÙŠÙ„ Ø²Ø§Ø¦Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¶Ø®Ø©",
        "Incident: Shutdown" if lang=="en" else "Ø­Ø§Ø¯Ø«: Ø¥ÙŠÙ‚Ø§Ù"
    ), unsafe_allow_html=True)
    st.markdown('<div class="ai-action-bar">', unsafe_allow_html=True)
    if st.button(T["ai_rootcause_btn"], key="ai_rootcause_btn_rootcause"):
        summary = ask_llm_advanced(
            prompt="Given this root cause diagram, explain why the incident happened and recommend preventative actions.",
            lang=lang,
            root_cause="Methane leak led to compressor 2 fault, which overloaded the pump, leading to shutdown."
        )
        st.info(rtl_wrap(summary))
    st.markdown('</div>', unsafe_allow_html=True)

elif section == T["side_sections"][9]:  # AI Copilot Chat (LLM)
    show_logo()
    st.markdown(f'<div class="{"gradient-ar" if rtl else "gradient-header"}">{T["side_sections"][9]}</div>', unsafe_allow_html=True)
    st.markdown(rtl_wrap("Ask the AI about plant issues, troubleshooting, or improvements." if lang=="en" else "Ø§Ø³Ø£Ù„ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„ØµÙ†Ø§Ø¹ÙŠ Ø¹Ù† Ø§Ù„Ø£Ø¹Ø·Ø§Ù„ Ø£Ùˆ Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª Ø£Ùˆ Ø§Ù„ØªØ´ØºÙŠÙ„."))
    user_prompt = st.text_input(("Ask AI a question..." if lang=="en" else "Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ø§Ù‹ Ù„Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„ØµÙ†Ø§Ø¹ÙŠ..."), key="ai_input")
    ai_context = {
        "kpis": demo_df.tail(12).mean().to_dict(),
        "alerts": ["High Temp", "Methane Spike"] if lang == "en" else ["Ø­Ø±Ø§Ø±Ø© Ø¹Ø§Ù„ÙŠØ©", "Ø§Ø±ØªÙØ§Ø¹ Ø§Ù„Ù…ÙŠØ«Ø§Ù†"],
    }
    if user_prompt:
        with st.spinner("Thinking..." if lang=="en" else "ÙŠÙÙƒØ±..."):
            # Root cause detection: if user asks "why", "cause", "root", etc.
            if any(w in user_prompt.lower() for w in ["why", "cause", "root", "Ø³Ø¨Ø¨", "Ø¬Ø°Ø±", "Ù„Ù…Ø§Ø°Ø§"]):
                root_cause = "Recent temperature and methane spikes, compressor fault, and delayed maintenance"
            else:
                root_cause = None
            answer = ask_llm_advanced(user_prompt, lang, context=str(ai_context), root_cause=root_cause)
        st.markdown(f"<div class='feedback-bubble'><b>AI:</b> {answer}</div>", unsafe_allow_html=True)
    st.markdown('<div class="ai-action-bar">', unsafe_allow_html=True)
    if st.button(T["ai_energy_btn"], key="ai_energy_btn_copilot"):
        ai_energy = ask_llm_advanced(
            prompt="Analyze current plant energy usage and recommend optimization actions.",
            lang=lang,
            context=f"KPIs: {ai_context['kpis']}"
        )
        st.info(rtl_wrap(ai_energy))
    st.markdown('</div>', unsafe_allow_html=True)

elif section == T["side_sections"][10]:  # Live Plant 3D
    show_logo()
    st.markdown(f'<div class="{"gradient-ar" if rtl else "gradient-header"}">{T["live3d_header"]}</div>', unsafe_allow_html=True)
    st.markdown(rtl_wrap(T["live3d_intro"]), unsafe_allow_html=True)
    try:
        st.components.v1.iframe(
            "https://sketchfab.com/models/6ebc4e240be94b8caa1e1e6b0f2e3e7b/embed", height=480, scrolling=True
        )
        st.markdown(
            rtl_wrap(
                '<sup>3D model courtesy of <a href="https://sketchfab.com" target="_blank">Sketchfab</a></sup>' if lang=="en"
                else '<sup>Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø«Ù„Ø§Ø«ÙŠ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ù…Ù‚Ø¯Ù… Ù…Ù† <a href="https://sketchfab.com" target="_blank">Sketchfab</a></sup>'
            ),
            unsafe_allow_html=True
        )
    except Exception:
        st.markdown(f'<div class="peak-card" style="background:#fa709a22">{T["live3d_404"]}</div>', unsafe_allow_html=True)
    st.image(
        "https://cdn.pixabay.com/photo/2016/11/29/10/07/architecture-1868667_1280.jpg",
        caption=rtl_wrap(T["static_3d_caption"])
    )

elif section == T["side_sections"][11]:  # Incident Timeline
    show_logo()
    st.markdown(f'<div class="{"gradient-ar" if rtl else "gradient-header"}">{T["side_sections"][11]}</div>', unsafe_allow_html=True)
    timeline_steps = [
        ("2025-06-30 11:23", "ğŸ›‘", "Methane leak detected at Compressor 2. Emergency shutdown triggered."),
        ("2025-06-30 10:58", "âš ï¸", "Flow rate anomaly at Pump 1. Operator notified."),
        ("2025-06-30 10:50", "â„¹ï¸", "Temperature rising at Reactor. Trend within safe limits.")
    ] if lang == "en" else [
        ("2025-06-30 11:23", "ğŸ›‘", "Ø§ÙƒØªØ´Ø§Ù ØªØ³Ø±Ø¨ Ù…ÙŠØ«Ø§Ù† Ø¹Ù†Ø¯ Ø§Ù„Ø¶Ø§ØºØ· Ù¢. Ø¥ÙŠÙ‚Ø§Ù Ø·Ø§Ø±Ø¦ ØªÙ„Ù‚Ø§Ø¦ÙŠ."),
        ("2025-06-30 10:58", "âš ï¸", "Ø´Ø°ÙˆØ° ØªØ¯ÙÙ‚ Ø¹Ù†Ø¯ Ù…Ø¶Ø®Ø© Ù¡. ØªÙ… Ø¥Ø®Ø·Ø§Ø± Ø§Ù„Ù…Ø´ØºÙ„."),
        ("2025-06-30 10:50", "â„¹ï¸", "Ø§Ø±ØªÙØ§Ø¹ Ø§Ù„Ø­Ø±Ø§Ø±Ø© Ø¨Ø§Ù„Ù…ÙØ§Ø¹Ù„. Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø¶Ù…Ù† Ø§Ù„Ø­Ø¯ÙˆØ¯ Ø§Ù„Ø¢Ù…Ù†Ø©.")
    ]
    for t, icon, desc in timeline_steps:
        st.markdown(
            f"""<div class="timeline-step"><span class="timeline-icon">{icon}</span>
            <b>{t}</b><br>
            <span style="font-size:1.07em">{desc}</span></div>""",
            unsafe_allow_html=True
        )

elif section == T["side_sections"][12]:  # Energy Optimization
    show_logo()
    st.markdown(f'<div class="{"gradient-ar" if rtl else "gradient-header"}">{T["side_sections"][12]}</div>', unsafe_allow_html=True)
    st.markdown(rtl_wrap("Monitor and optimize plant energy use. AI recommendations below." if lang=="en" else "Ø±Ø§Ù‚Ø¨ ÙˆØ­Ø³Ù† Ø§Ø³ØªÙ‡Ù„Ø§Ùƒ Ø§Ù„Ø·Ø§Ù‚Ø©. ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø£Ø¯Ù†Ø§Ù‡."))
    energy_sect = ["Compressor", "Pump", "Lighting", "Other"] if lang=="en" else ["Ø¶Ø§ØºØ·", "Ù…Ø¶Ø®Ø©", "Ø¥Ø¶Ø§Ø¡Ø©", "Ø£Ø®Ø±Ù‰"]
    vals = [51, 28, 9, 12]
    fig = px.bar(x=energy_sect, y=vals, color=energy_sect, color_discrete_sequence=px.colors.sequential.Plasma)
    fig.update_layout(height=230, margin=dict(l=10, r=10, t=10, b=10), showlegend=False)
    st.plotly_chart(fig, use_container_width=True)
    energy_recos = [
        ("Reduce compressor load during peak hours", "âš¡"),
        ("Schedule maintenance for low demand windows", "ğŸ› ï¸")
    ] if lang == "en" else [
        ("ØªØ®ÙÙŠØ¶ ØªØ´ØºÙŠÙ„ Ø§Ù„Ø¶ÙˆØ§ØºØ· Ø£ÙˆÙ‚Ø§Øª Ø§Ù„Ø°Ø±ÙˆØ©", "âš¡"),
        ("Ø¬Ø¯ÙˆÙ„Ø© Ø§Ù„ØµÙŠØ§Ù†Ø© Ø£ÙˆÙ‚Ø§Øª Ø§Ù„Ø·Ù„Ø¨ Ø§Ù„Ù…Ù†Ø®ÙØ¶", "ğŸ› ï¸")
    ]
    for txt, icon in energy_recos:
        st.markdown(f"""<div class="peak-card" style="background:#e0eafc;margin-bottom:0.6em;">
            <span class="timeline-icon">{icon}</span> {txt}
        </div>""", unsafe_allow_html=True)
    st.markdown('<div class="ai-action-bar">', unsafe_allow_html=True)
    if st.button(T["ai_energy_btn"], key="ai_energy_btn_energy"):
        ai_energy = ask_llm_advanced(
            prompt="Analyze plant energy usage and suggest optimization for each sector. Use the following as input.",
            lang=lang,
            context=f"Energy sectors: {dict(zip(energy_sect, vals))}"
        )
        st.info(rtl_wrap(ai_energy))
    st.markdown('</div>', unsafe_allow_html=True)

elif section == T["side_sections"][13]:  # Future Insights
    show_logo()
    st.markdown(f'<div class="{"gradient-ar" if rtl else "gradient-header"}">{T["side_sections"][13]}</div>', unsafe_allow_html=True)
    st.markdown("<div style='display:flex;gap:1.3em;flex-wrap:wrap;'>", unsafe_allow_html=True)
    future_cards = [
        ("Predictive Risk Alert", "AI models forecast a risk spike for methane at Compressor 2 next week.", "ğŸš¨"),
        ("Efficiency Opportunity", "Upgrade control logic to boost plant efficiency by 3%.", "ğŸŒ±")
    ] if lang == "en" else [
        ("ØªÙ†Ø¨ÙŠÙ‡ Ù…Ø®Ø§Ø·Ø± ØªÙ†Ø¨Ø¤ÙŠ", "ÙŠØªÙˆÙ‚Ø¹ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø§Ø±ØªÙØ§Ø¹ Ø§Ù„Ù…ÙŠØ«Ø§Ù† Ø¹Ù†Ø¯ Ø§Ù„Ø¶Ø§ØºØ· Ù¢ Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ Ø§Ù„Ù‚Ø§Ø¯Ù….", "ğŸš¨"),
        ("ÙØ±ØµØ© ÙƒÙØ§Ø¡Ø©", "ØªØ­Ø¯ÙŠØ« Ù…Ù†Ø·Ù‚ Ø§Ù„ØªØ­ÙƒÙ… Ù„Ø±ÙØ¹ Ø§Ù„ÙƒÙØ§Ø¡Ø© Ù£Ùª.", "ğŸŒ±")
    ]
    for title, desc, icon in future_cards:
        st.markdown(f"""<div class="peak-card" style="min-width:220px;max-width:330px;">
            <span style="font-size:2.1em;">{icon}</span><br>
            <b>{title}</b><br>
            <span style="font-size:1.09em">{desc}</span>
        </div>""", unsafe_allow_html=True)
    x = [datetime.now() + timedelta(days=i) for i in range(7)]
    y = [1.2,1.5,2.0,2.8,3.6,3.9,4.8]
    fig = go.Figure()
    fig.add_trace(go.Scatter(x=x, y=y, mode="lines+markers", line=dict(color="#fa709a", width=3), name="Methane Risk"))
    fig.update_layout(height=200, margin=dict(l=10, r=10, t=10, b=10), title=("Methane Risk Forecast" if lang=="en" else "ØªÙˆÙ‚Ø¹ Ù…Ø®Ø§Ø·Ø± Ø§Ù„Ù…ÙŠØ«Ø§Ù†"))
    st.plotly_chart(fig, use_container_width=True)
    st.markdown("</div>", unsafe_allow_html=True)

elif section == T["side_sections"][14]:  # Operator Feedback
    show_logo()
    st.markdown(f'<div class="{"gradient-ar" if rtl else "gradient-header"}">{T["side_sections"][14]}</div>', unsafe_allow_html=True)
    feedback = st.text_area(rtl_wrap("Add operator feedback or incident note:" if lang=="en" else "Ø£Ø¶Ù Ù…Ù„Ø§Ø­Ø¸Ø© Ø£Ùˆ Ù…Ù„Ø§Ø­Ø¸Ø© Ø­Ø§Ø¯Ø« Ù„Ù„Ù…Ø´ØºÙ„:"), key="feedbackbox")
    if st.button("Submit Feedback" if lang=="en" else "Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø©"):
        if feedback.strip():
            st.session_state["feedback_list"].append((datetime.now().strftime("%Y-%m-%d %H:%M"), feedback.strip()))
    for t, fb in reversed(st.session_state["feedback_list"]):
        st.markdown(f"<div class='feedback-bubble'>{rtl_wrap(f'**[{t}]** {fb}')}</div>", unsafe_allow_html=True)
    st.markdown('<div class="ai-action-bar">', unsafe_allow_html=True)
    if st.button(T["ai_feedback_btn"], key="ai_feedback_btn"):
        notes_concat = " ".join([fb for _, fb in st.session_state["feedback_list"]])
        ai_summary = ask_llm_advanced(
            prompt="Summarize the main trends and concerns from recent operator feedback.",
            lang=lang,
            context=notes_concat
        )
        st.success(rtl_wrap(ai_summary))
    st.markdown('</div>', unsafe_allow_html=True)

elif section == T["side_sections"][15]:  # About
    show_logo()
    st.markdown(f'<div class="{"gradient-ar" if rtl else "gradient-header"}">{T["about_header"]}</div>', unsafe_allow_html=True)
    st.markdown(f"<div class='about-bgcard'>", unsafe_allow_html=True)
    st.markdown(
        "".join([
            f"<span class='about-color' style='background:{color}30;color:{color}'>{value}</span> "
            for color, value in T["about_colorful"]
        ]), unsafe_allow_html=True
    )
    st.markdown(f"<div class='about-story'>{rtl_wrap(T['about_story'])}</div>", unsafe_allow_html=True)
    st.markdown(rtl_wrap("<div class='about-feature'>Features</div>") if lang=="en" else rtl_wrap("<div class='about-feature'>Ø§Ù„Ù…ÙŠØ²Ø§Øª</div>"), unsafe_allow_html=True)
    st.markdown("<ul>"+"".join([f"<li>{f}</li>" for f in T["features"]])+"</ul>", unsafe_allow_html=True)
    st.markdown(rtl_wrap("<div class='about-feature'>How to extend</div>") if lang=="en" else rtl_wrap("<div class='about-feature'>ÙƒÙŠÙÙŠØ© Ø§Ù„ØªÙˆØ³ÙŠØ¹</div>"), unsafe_allow_html=True)
    st.markdown("<ul>"+"".join([f"<li>{f}</li>" for f in T["howto_extend"]])+"</ul>", unsafe_allow_html=True)
    st.markdown(rtl_wrap("<div class='about-contact'><b>Contact</b></div>") if lang=="en" else rtl_wrap("<div class='about-contact'><b>ØªÙˆØ§ØµÙ„ Ù…Ø¹Ù†Ø§</b></div>"), unsafe_allow_html=True)
    for name, mail, phone in T["developers"]:
        st.markdown(f"{T['contact']}: {name}<br>Email: <a href='mailto:{mail}'>{mail}</a><br>Phone: {phone}<br>", unsafe_allow_html=True)
    st.markdown(rtl_wrap(f"<i>{T['demo_note']}</i>"), unsafe_allow_html=True)
    st.markdown("</div>", unsafe_allow_html=True)
